{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f364f90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifification  is our problem\n",
      "\n",
      "0  experiment:\n",
      "\n",
      "[[-10.92272505  -9.29478857  -6.21110455]\n",
      " [-35.28477004  38.86293517  -4.954755  ]\n",
      " [ 51.1500123  -14.677888    13.19876093]\n",
      " ...\n",
      " [-93.06118111  22.15037032   2.46565424]\n",
      " [-95.11956802  25.60355968  -3.82380589]\n",
      " [-90.63083864 -28.27771986  -4.57548287]] reduced_datatrain\n",
      "\n",
      "[0.8572631  0.07561149 0.03582277] variance_scoretrain\n",
      "\n",
      "1  experiment:\n",
      "\n",
      "[[129.46964732  11.63017101   2.11365406]\n",
      " [208.57798741  28.2577262  -10.9060684 ]\n",
      " [-77.08269566  -2.26574547 -23.36877114]\n",
      " ...\n",
      " [-75.24592199 -17.11965938 -18.38085852]\n",
      " [-70.71684327 -56.47851787   5.98185911]\n",
      " [-75.62232152  10.45904004 -15.93669904]] reduced_datatrain\n",
      "\n",
      "[0.8976209  0.0577072  0.02344864] variance_scoretrain\n",
      "\n",
      "2  experiment:\n",
      "\n",
      "[[-90.96844516  20.53603686  -8.49300816]\n",
      " [102.15605047 -10.80632781   7.63984192]\n",
      " [-91.62187553   6.0037081   -4.08060999]\n",
      " ...\n",
      " [ 32.23782907  -0.93314994   0.63300589]\n",
      " [ 14.35958941   8.59213335  -1.48182944]\n",
      " [-91.47179301   3.11921876   6.11913532]] reduced_datatrain\n",
      "\n",
      "[0.84270181 0.08965486 0.0349356 ] variance_scoretrain\n",
      "\n",
      "3  experiment:\n",
      "\n",
      "[[ 11.88852267  18.29473344   3.96029881]\n",
      " [-78.31044321 -29.12432049 -13.68527915]\n",
      " [-83.5117699    0.14769668  -7.81723357]\n",
      " ...\n",
      " [-86.357427    26.41549267  66.19848302]\n",
      " [-81.63088701  -0.81615594 -16.34904809]\n",
      " [-80.63887089  -2.50909573  -0.92306296]] reduced_datatrain\n",
      "\n",
      "[0.87003515 0.07061604 0.02923947] variance_scoretrain\n",
      "\n",
      "4  experiment:\n",
      "\n",
      "[[-15.56584368  20.01694863 -10.933027  ]\n",
      " [ 82.87769092  26.64416465  10.98595495]\n",
      " [-18.57976741  30.54619873  10.71203657]\n",
      " ...\n",
      " [-81.76298007   0.88779621 -17.50696985]\n",
      " [-29.41543228  42.96992305  -4.99290231]\n",
      " [ 19.1753724   16.56919635  -8.8546344 ]] reduced_datatrain\n",
      "\n",
      "[0.90288472 0.05657514 0.0199118 ] variance_scoretrain\n",
      "\n",
      "[0.66558442 0.6461039  0.66558442 0.59415584 0.66558442]  nn_all\n",
      "\n",
      "0.6474025974025974  mean nn_all\n",
      "\n",
      "0.02767178669176953  std nn_all\n",
      "\n",
      "[0.73376623 0.74025974 0.74025974 0.72077922 0.74350649]  tree_all\n",
      "\n",
      "0.7357142857142858  mean - nn pca _all\n",
      "\n",
      "0.008110387010907041  std - nn - pca _all\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "import random\n",
    "\n",
    "from sklearn import datasets \n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def read_data(run_num, prob):\n",
    "\n",
    "    normalise = False\n",
    "    \n",
    "    if prob == 'classifification': \n",
    "        # Source: Pima-Indian diabetes dataset - https://www.kaggle.com/kumargh/pimaindiansdiabetescsv\n",
    "        data_in = genfromtxt(\"datasets/pima.csv\", delimiter=\",\")\n",
    "        data_inputx = data_in[:, 0:8]  # all features 0-7 \n",
    "        data_inputy = data_in[:, -1]   # this is target - so that last col is selected from data\n",
    "\n",
    "    elif prob == 'regression':   # energy - regression prob\n",
    "        data_in = genfromtxt('datasets/energy/ENB2012_data.csv', delimiter=\",\")  # you can replace this with Abalone\n",
    "        data_inputx = data_in[:, 0:8]  # all features 0-7\n",
    "        data_inputy = data_in[:, 8]    # this is target - just the heating load selected from data  \n",
    "\n",
    "    if normalise == True:\n",
    "        transformer = Normalizer().fit(data_inputx)    # fit does nothing\n",
    "        data_inputx = transformer.transform(data_inputx)\n",
    " \n",
    "    x_train, x_test, y_train, y_test = train_test_split(data_inputx, data_inputy, test_size=0.40, random_state=run_num)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def dimen_reduction(x_train, x_test, type_model):\n",
    "\n",
    "    # Scikit-learn is using SVD for PCA\n",
    "\n",
    "    if type_model == 0:   # SVD solver - full\n",
    "        pca = PCA(n_components=3, svd_solver='full')    # SVD LAPACK Solver\n",
    "        \n",
    "    elif type_model == 1: # SVD \n",
    "        pca = PCA(n_components=3, svd_solver='arpack')  # SVD AROACK Solver\n",
    "\n",
    "    # note number of components can be changed to 0.95\n",
    "    # but since we have different train and test data, that can create problems\n",
    "    # it is best to combine both train and test data and then split them back again\n",
    "\n",
    "    #data = np.vstack((x_train, x_test))   # something along these lines\n",
    "\n",
    "    #print(data.shape, ' * ')\n",
    "\n",
    "    reduced_datatrain = pca.fit_transform(x_train)\n",
    "    train_varianceratio = pca.explained_variance_ratio_\n",
    "\n",
    "    reduced_datatest = pca.fit_transform(x_test)\n",
    "    test_varianceratio = pca.explained_variance_ratio_\n",
    "\n",
    "    return reduced_datatrain, reduced_datatest, test_varianceratio, train_varianceratio\n",
    " \n",
    "    \n",
    "def scipy_models(x_train, x_test, y_train, y_test, type_model, hidden, learn_rate, run_num, problem): \n",
    "\n",
    "    if problem == 'classifification':\n",
    "        if type_model == 0:   # SGD \n",
    "            model = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, \n",
    "                                  max_iter=100, solver='sgd', learning_rate_init=learn_rate )\n",
    "            \n",
    "        elif type_model == 1:  # https://scikit-learn.org/stable/modules/tree.html (see how tree can be visualised)\n",
    "            model = DecisionTreeClassifier(random_state=0, max_depth=tree_depth) \n",
    "            \n",
    "        elif type_model == 2:\n",
    "            model = RandomForestClassifier(n_estimators=100, max_depth=tree_depth, random_state=run_num)             \n",
    "\n",
    "    elif problem == 'regression':\n",
    "        if type_model == 0:    # SGD  \n",
    "            model = MLPRegressor(hidden_layer_sizes=(hidden*3,), random_state=run_num, \n",
    "                                 max_iter=500, solver='adam', learning_rate_init=learn_rate) \n",
    "            \n",
    "        elif type_model == 1:  \n",
    "            model = DecisionTreeRegressor(random_state=0, max_depth=tree_depth)\n",
    "            \n",
    "        elif type_model == 2: \n",
    "            model = RandomForestRegressor(n_estimators=100, max_depth=tree_depth, random_state=run_num)        \n",
    "   \n",
    "\n",
    "    # Train the model using the training sets\n",
    "    model.fit(x_train, y_train)   \n",
    "\n",
    "    if type_model == 1:\n",
    "        r = export_text(model)\n",
    "        print(\"\\n\", r)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train) \n",
    "\n",
    "    if problem == 'regression':\n",
    "        perf_test = np.sqrt(mean_squared_error(y_test, y_pred_test)) \n",
    "        perf_train = np.sqrt(mean_squared_error(y_train, y_pred_train)) \n",
    "\n",
    "    if problem == 'classifification': \n",
    "        perf_test = accuracy_score(y_pred_test, y_test) \n",
    "        perf_train = accuracy_score(y_pred_train, y_train) \n",
    "        cm = confusion_matrix(y_pred_test, y_test) \n",
    "        #print(cm, 'is confusion matrix')\n",
    "        #auc = roc_auc_score(y_pred, y_test, average=None) \n",
    "\n",
    "    return perf_test #,perf_train\n",
    "\n",
    "\n",
    "def main(): \n",
    "\n",
    "    max_expruns = 5\n",
    "\n",
    "    nn_all = np.zeros(max_expruns) \n",
    "    nnpca_all = np.zeros(max_expruns)   \n",
    "\n",
    "    learn_rate = 0.01\n",
    "    hidden = 8\n",
    "\n",
    "    prob = 'classifification' # classification or regression \n",
    "    #prob = 'regression'       # classification or regression \n",
    "\n",
    "    # classifcation accurary is reported for classification and RMSE for regression\n",
    "\n",
    "    print(prob, ' is our problem\\n') \n",
    " \n",
    "    for run_num in range(0, max_expruns): \n",
    "        \n",
    "        print(run_num, \" experiment:\\n\")\n",
    "\n",
    "        x_train, x_test, y_train, y_test = read_data(run_num, prob)   \n",
    "        \n",
    "        acc_nn = scipy_models(x_train, x_test, y_train, y_test, 0, hidden, learn_rate, run_num, prob) # SGD \n",
    "\n",
    "        # 0 is for PCA (you can try 1 for case of SVD)\n",
    "        [reduced_datatrain, reduced_datatest, variance_scoretrain, variance_scoretest] = dimen_reduction(x_train, x_test, 1) \n",
    "\n",
    "        print(reduced_datatrain, 'reduced_datatrain\\n')\n",
    "        print(variance_scoretrain, 'variance_scoretrain\\n')\n",
    "\n",
    "        # SGD after PCA\n",
    "        acc_nnpca = scipy_models(reduced_datatrain, reduced_datatest, y_train, y_test, 0, hidden, learn_rate, run_num, prob) \n",
    "               \n",
    "        nn_all[run_num] = acc_nn\n",
    "        nnpca_all[run_num] = acc_nnpca\n",
    "        \n",
    "    print(nn_all,' nn_all\\n')\n",
    "    print(np.mean(nn_all), ' mean nn_all\\n')\n",
    "    print(np.std(nn_all), ' std nn_all\\n')\n",
    " \n",
    "    print(nnpca_all,  ' tree_all\\n')\n",
    "    print(np.mean(nnpca_all),  ' mean - nn pca _all\\n')\n",
    "    print(np.std(nnpca_all),  ' std - nn - pca _all\\n') \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "     main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41923fb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
