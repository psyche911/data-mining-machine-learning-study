{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0bc829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5b1bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([-4., -2.,  0.,  2.,  4.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(-4, 4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88786ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "candidates = {'gmat': [780,750,690,710,680,730,690,720,740,690,610,690,710,680,770,610,580,650,540,590,620,600,550,550,570,670,660,580,650,660,640,620,660,660,680,650,670,580,590,690],\n",
    "              'gpa': [4,3.9,3.3,3.7,3.9,3.7,2.3,3.3,3.3,1.7,2.7,3.7,3.7,3.3,3.3,3,2.7,3.7,2.7,2.3,3.3,2,2.3,2.7,3,3.3,3.7,2.3,3.7,3.3,3,2.7,4,3.3,3.3,2.3,2.7,3.3,1.7,3.7],\n",
    "              'work_experience': [3,4,3,5,4,6,1,4,5,1,3,5,6,4,3,1,4,6,2,3,2,1,4,1,2,6,4,2,6,5,1,2,4,6,5,1,2,1,4,5],\n",
    "              'admitted': [1,1,0,1,0,1,0,1,1,0,0,1,1,0,1,0,0,1,0,0,1,0,0,0,0,1,1,0,1,1,0,0,1,1,1,0,0,0,0,1]\n",
    "              }\n",
    "\n",
    "df = pd.DataFrame(candidates,columns= ['gmat', 'gpa','work_experience','admitted'])\n",
    "\n",
    "X = df[['gmat', 'gpa','work_experience']]\n",
    "y = df['admitted']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()\n",
    "plt.savefig(\"figures/confmat_test.png\")\n",
    "\n",
    "acc_score = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score: \", acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d3e7869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[590.    2.    3.    0. ]\n",
      " [740.    3.7   4.    1. ]\n",
      " [680.    3.3   6.    1. ]\n",
      " [610.    2.3   1.    0. ]\n",
      " [710.    3.    5.    1. ]]\n"
     ]
    }
   ],
   "source": [
    "new_candidates = {'gmat': [590,740,680,610,710],\n",
    "                  'gpa': [2,3.7,3.3,2.3,3],\n",
    "                  'work_experience': [3,4,6,1,5]\n",
    "                  }\n",
    "\n",
    "df2 = pd.DataFrame(new_candidates, columns = ['gmat', 'gpa','work_experience'])\n",
    "df3 = df2.values\n",
    "\n",
    "y_pred2 = log_reg.predict(df2)\n",
    "\n",
    "results = np.hstack((df3, y_pred2[:, np.newaxis]))\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a29ede86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[590. ,   2. ,   3. ],\n",
       "       [740. ,   3.7,   4. ],\n",
       "       [680. ,   3.3,   6. ],\n",
       "       [610. ,   2.3,   1. ],\n",
       "       [710. ,   3. ,   5. ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2.values\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6866a4df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a8c8d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f720f0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[590. ,   2. ,   3. ,   0. ],\n",
       "       [740. ,   3.7,   4. ,   1. ],\n",
       "       [680. ,   3.3,   6. ,   1. ],\n",
       "       [610. ,   2.3,   1. ,   0. ],\n",
       "       [710. ,   3. ,   5. ,   1. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((df3, y_pred2[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e7370dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admitted\n",
       "0         1\n",
       "1         1\n",
       "2         0\n",
       "3         1\n",
       "4         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['admitted']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828f6840",
   "metadata": {},
   "source": [
    "Implement logistic-regression-stochastic-gradient-descent scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66ea920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=0.300, error=2.217\n",
      ">epoch=1, lrate=0.300, error=1.613\n",
      ">epoch=2, lrate=0.300, error=1.113\n",
      ">epoch=3, lrate=0.300, error=0.827\n",
      ">epoch=4, lrate=0.300, error=0.623\n",
      ">epoch=5, lrate=0.300, error=0.494\n",
      ">epoch=6, lrate=0.300, error=0.412\n",
      ">epoch=7, lrate=0.300, error=0.354\n",
      ">epoch=8, lrate=0.300, error=0.310\n",
      ">epoch=9, lrate=0.300, error=0.276\n",
      "[-0.4066054639903037, 0.8525733163581036, -1.1047462590413233]\n"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "# Make a prediction with coefficients\n",
    "def predict(row, coefficients):\n",
    "    yhat = coefficients[0]     # y-intercept\n",
    "    for i in range(len(row) - 1):\n",
    "        yhat += coefficients[i+1] * row[i]\n",
    "    return 1.0/(1.0 + exp(-yhat))\n",
    "\n",
    "# Estimate logistic regression coefficients using stochastic gradient descent\n",
    "def coefficients_sgd(train, learning_rate, n_epoch):\n",
    "    coef = [0.0 for i in range(len(train[0]))]\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            yhat = predict(row, coef)   # sigmoid function\n",
    "            error = row[-1] - yhat      # last column := target\n",
    "            sum_error += error**2\n",
    "            coef[0] = coef[0] + learning_rate * error * yhat * (1 - yhat)\n",
    "            '''\n",
    "            yhat * (1 - yhat) := differentiation of yhat\n",
    "            gradient\n",
    "            '''            \n",
    "            for i in range(len(row)-1):\n",
    "                coef[i+1] = coef[i+1] + learning_rate * error * yhat * (1.0-yhat) * row[i]\n",
    "        print('>epoch=%d, learning_rate=%.3f, error=%.3f' % (epoch, learning_rate, sum_error))\n",
    "    return coef\n",
    "\n",
    "# Calculate coefficients\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "           [1.465489372,2.362125076,0],\n",
    "           [3.396561688,4.400293529,0],\n",
    "           [1.38807019,1.850220317,0],\n",
    "           [3.06407232,3.005305973,0],\n",
    "           [7.627531214,2.759262235,1],\n",
    "           [5.332441248,2.088626775,1],\n",
    "           [6.922596716,1.77106367,1],\n",
    "           [8.675418651,-0.242068655,1],\n",
    "           [7.673756466,3.508563011,1]]\n",
    "learning_rate = 0.3\n",
    "n_epoch = 10\n",
    "coef = coefficients_sgd(dataset, learning_rate, n_epoch)\n",
    "print(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a8bf978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\dimao\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass dual=[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]], tol=[[0 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [1 1 0]], C=2, fit_intercept=0.9 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'SGD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-c3c15e741740>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-c3c15e741740>\u001b[0m in \u001b[0;36mLogisticRegression\u001b[1;34m()\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[0mlog_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epocs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxor_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxor_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mtrain_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mtrain_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_perc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'SGD'"
     ]
    }
   ],
   "source": [
    "from math import exp\n",
    "\n",
    "SIGMOID = 1\n",
    "STEP = 2\n",
    "LINEAR = 3\n",
    "\n",
    "random.seed()\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, num_epocs, train_data, test_data, num_features, learn_rate):\n",
    "        self.train_data = train_data\n",
    "        self.test_data = test_data\n",
    "        self.num_features = num_features\n",
    "        self.num_outputs = self.train_data.shape[1] - num_features   # number of targets\n",
    "        self.num_train = self.train_data.shape[0]    # number of rows\n",
    "        self.w = np.random.uniform(-0.5, 0.5, num_features)\n",
    "        self.b = np.random.uniform(-0.5, 0.5, self.num_outputs)\n",
    "        self.learn_rate = learn_rate\n",
    "        self.max_epoch = num_epocs\n",
    "        self.use_activation = SIGMOID\n",
    "        self.out_delta = np.zeros(self.num_outputs)\n",
    "        \n",
    "        print(\"self.w init: \", self.w)\n",
    "        print(\"self.b init: \", self.b)\n",
    "        print(\"out_delta: \", self.out_delta)\n",
    "        \n",
    "    def activation_func(self, z_vec):\n",
    "        if self.use_activation == SIGMOID:\n",
    "            y = 1 / (1 + np.exp(z_vec))    # sigmoid function\n",
    "        elif self.use_activation == STEP:\n",
    "            y = (z_vec > 0).astype(int)    # if greater than 0, use 1, else 0\n",
    "        else:\n",
    "            y = z_vec\n",
    "        return y\n",
    "    \n",
    "    def predict(self, x_vec):\n",
    "        z_vec = x_vec.dot(self.w) - self.b   # linear output\n",
    "        output = self.activation_func(z_vec)\n",
    "        return output\n",
    "    \n",
    "    def gradient(self, x_vec, output, actual):\n",
    "        if self.use_activation == SIGMOID:\n",
    "            out_delta = (output - actual) * (output * (1 - output))\n",
    "        else:\n",
    "            out_delta = output - actual\n",
    "        return out_delta\n",
    "    \n",
    "    def update(self, x_vec, output, actual):\n",
    "        self.w += self.learn_rate * (x_vec * self.out_delta)\n",
    "        self.b += (1 * self.learn_rate * self.output_delta)\n",
    "        \n",
    "    def squared_error(self, prediction, actual):\n",
    "        return np.sum(np.square(prediction - actual))/prediction.shape[0]\n",
    "    \n",
    "    def test_model(self, data, tolerance):\n",
    "        num_instances = data.shape[0]   # number of rows\n",
    "        class_perf = 0\n",
    "        sum_sqer = 0\n",
    "        \n",
    "        for s in range(num_instances):\n",
    "            input_instance = self.train_data[s, 0:self.num_features]\n",
    "            actual = self.train_data[s, self.num_features:]\n",
    "            prediction = self.predict(input_instance)\n",
    "            sum_sqer += self.squared_error(prediction, actual)\n",
    "            \n",
    "            pred_binary = np.where(prediction > (1 - tolerance), 1, 0)\n",
    "            \n",
    "            print('s, actual, prediction, sum_sqer: \\n', s, actual, prediction, pred_binary, sum_sqer)\n",
    "            \n",
    "            if (actual == pred_binary).all():\n",
    "                class_perf += 1\n",
    "                \n",
    "        rmse = np.sqrt(sum_sqer/num_instances)\n",
    "        percentage_correct = float(class_perf/num_instances)*100\n",
    "        print(\"class_perf, rmse\\n\", percentage_correct, rmse)\n",
    "        return rmse, percentage_correct\n",
    "    \n",
    "    def SGD(self):\n",
    "        epoch = 0\n",
    "        shuffle = True\n",
    "        while epoch < self.max_epoch:\n",
    "            sum_sqer = 0\n",
    "            for s in range(self.num_train):    # num_train := number of rows\n",
    "                if shuffle == True:\n",
    "                    i = random.randint(0, self.num_train-1)  # generate a random integer between 0 and (self.num_train-1)\n",
    "                input_instance = self.train_data[i, 0:self.num_features]\n",
    "                actual = self.train_data[i, self.num_features:]\n",
    "                prediction = self.predict(input_instance)\n",
    "                sum_sqer += self.squared_error(prediction, actual)\n",
    "                self.out_delta = self.gradient(input_instance, prediction, actual)\n",
    "                self.update(input_instance, prediction, actual)\n",
    "                \n",
    "            print(epoch, sum_sqer, self.w, self.b)\n",
    "            epoch += 1\n",
    "            \n",
    "        rmse_train, train_perc = self.test_model(self.train_data, 0.3)\n",
    "        rmse_test = 0\n",
    "        test_perc = 0\n",
    "        return train_perc, test_perc, rmse_train, rmse_test\n",
    "    \n",
    "    def GD(self):\n",
    "        epoch = 0\n",
    "        while epoch < self.max_epoch:\n",
    "            sum_sqer = 0\n",
    "            for s in range(self.num_train):\n",
    "                input_instance = self.train_data[s, 0:self.num_features]\n",
    "                actual = self.train_data[s, self.num_features:]\n",
    "                prediction = self.predict(input_instance)\n",
    "                sum_sqer += self.squared_error(prediction, actual)\n",
    "                self.out_delta += self.gradient(input_instance, prediction, actual)\n",
    "            self.update(input_instance, prediction, actual)\n",
    "            \n",
    "            print(epoch, sum_sqer, self.w, self.b)\n",
    "            epoch += 1\n",
    "            \n",
    "        rmse_train, train_perc = self.test_model(self.train_data, 0.3)\n",
    "        rmse_test = 0\n",
    "        test_perc = 0\n",
    "        return train_perc, test_perc, rmse_train, rmse_test\n",
    "    \n",
    "    def main():\n",
    "        random.seed()\n",
    "        dataset = [[2.7810836,2.550537003,0],\n",
    "                    [1.465489372,2.362125076,0],\n",
    "                    [3.396561688,4.400293529,0],\n",
    "                    [1.38807019,1.850220317,0],\n",
    "                    [3.06407232,3.005305973,0],\n",
    "                    [7.627531214,2.759262235,1],\n",
    "                    [5.332441248,2.088626775,1],\n",
    "                    [6.922596716,1.77106367,1],\n",
    "                    [8.675418651,-0.242068655,1],\n",
    "                    [7.673756466,3.508563011,1]]\n",
    "        \n",
    "        train_data = np.asarray(dataset)\n",
    "        test_data = train_data\n",
    "        \n",
    "        learn_rate = 0.3\n",
    "        num_features = 2\n",
    "        num_epochs = 20\n",
    "        \n",
    "        print(train_data)\n",
    "        \n",
    "        log_reg = LogisticRegression(num_epocs, train_data, test_data, num_features, learn_rate)\n",
    "        train_perc, test_perc, rmse_train, rmse_test = log_reg.SGD()\n",
    "        train_perc, test_perc, rmse_train, rmse_test = log_reg.GD()\n",
    "        \n",
    "        xor_dataset = [[0,0,0],\n",
    "                       [0,1,1],\n",
    "                       [1,0,1],\n",
    "                       [1,1,0]]\n",
    "\n",
    "    xor_data = np.asarray(xor_dataset)   # convert list data to numpy\n",
    "    \n",
    "    num_epocs = 20\n",
    "    learn_rate = 0.9\n",
    "    num_features = 2\n",
    "    \n",
    "    log_reg = LogisticRegression(num_epocs, xor_data, xor_data, num_features, learn_rate)\n",
    "    (train_perc, test_perc, rmse_train, rmse_test) = log_reg.SGD()\n",
    "    (train_perc, test_perc, rmse_train, rmse_test) = log_reg.GD() \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b7c210f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7386818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xor_dataset = [[0,0,0],\n",
    "               [0,1,1],\n",
    "               [1,0,1],\n",
    "               [1,1,0]]\n",
    "type(xor_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d70e306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import seaborn as sns\\nimport matplotlib.pyplot as plt\\nimport numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(xor_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948fedf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
