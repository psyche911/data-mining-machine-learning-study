{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ea1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "\n",
    "def rmse(pred, actual):\n",
    "    return np.sqrt(((pred-actual)**2).mean())\n",
    "\n",
    "def main():\n",
    "    for i in range(1, 4):\n",
    "        problem = i\n",
    "        if problem == 1:\n",
    "            traindata = np.loadtxt(\"datasets/Lazer/train.txt\")\n",
    "            testdata = np.loadtxt(\"datasets/Lazer/test.txt\")\n",
    "            nam = \"Lazer\"\n",
    "\n",
    "        x_train = traindata[:, 0:3]\n",
    "        y_train = traindata[:, 4]\n",
    "        x_test = testdata[:, 0:3]\n",
    "        y_test = testdata[:, 4]\n",
    "\n",
    "        mlp_adam = MLPRegressor(hidden_layer_sizes=(5, ), activation='relu', \n",
    "                                solver='adam', alpha=0.1, max_iter=5000, tol=0)\n",
    "        \n",
    "        mlp_adam.fit(x_train,y_train)\n",
    "        y_predicttrain = mlp_adam.predict(x_train)\n",
    "        y_predicttest = mlp_adam.predict(x_test)\n",
    "        train_acc = rmse( y_predicttrain, y_train) \n",
    "        test_acc = rmse( y_predicttest, y_test) \n",
    "\n",
    "        print(name,train_acc, test_acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de835ff",
   "metadata": {},
   "source": [
    "### Neural network in scikit-learn for time series prediction\n",
    "- In the previous lesson, we covered different time series problems to train neural networks. This lesson demonstrates those time series problems using scikit-learn to show original data, scaled data set, and reconstructed datasets (train and test) for the different problems. \n",
    "\n",
    "- Let's learn how scikit-learn can be used for the regression problem where we use our time series data. Notice how the data is read and presented to the neural network and how the different training algorithms are used (SGD and Adam). You can use a sigmoid activation function as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e94826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the syntax used: \n",
    "\n",
    "# mlp_sgd = MLPRegressor(hidden_layer_sizes=(5, ), activation='relu', solver='sgd', alpha=0.1, max_iter=5000, tol=0)\n",
    "# mlp_sgd.fit(x_train,y_train)\n",
    "# y_predicttrain = mlp_sgd.predict(x_train)\n",
    "# y_predicttest = mlp_sgd.predict(x_test)\n",
    "# train_acc = rmse(y_predicttrain,y_train) \n",
    "# test_acc = rmse(y_predicttest, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8763ef7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lazer 0.13875699288932755 0.09678711217335256 \n",
      "\n",
      "Lazer 0.12909982815395218 0.09127108356805898 \n",
      "\n",
      "Lazer 0.01651944933495218 0.08718099587858463\n",
      "Sunspot 0.03684921868067299 0.02553653061993032 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\di_ma\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunspot 0.05085418443872117 0.03404902995859288 \n",
      "\n",
      "Sunspot 0.010861315846324791 0.018436820883625537\n",
      "Mackey 0.03192481486309106 0.03199499758570106 \n",
      "\n",
      "Mackey 0.03803419520510093 0.03811297620850551 \n",
      "\n",
      "Mackey 0.004884111664784808 0.011077287389406438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\di_ma\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#source: https://github.com/sydney-machine-learning/parallel-tempering-neural-net/blob/master/multicore-pt-regression/Compare_benchmark/nn.py\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "def rmse(pred, actual):\n",
    "    return np.sqrt(((pred-actual)**2).mean())\n",
    "\n",
    "def main():\n",
    "    for i in range(1, 4) : \n",
    "        problem = i\n",
    "        \n",
    "        if problem == 1:\n",
    "            traindata = np.loadtxt(\"datasets/Lazer/train.txt\")\n",
    "            testdata = np.loadtxt(\"datasets/Lazer/test.txt\")\n",
    "            name = \"Lazer\"\n",
    "            \n",
    "        if problem == 2:\n",
    "            traindata = np.loadtxt(\"datasets/Sunspot/train.txt\")\n",
    "            testdata = np.loadtxt(\"datasets/Sunspot/test.txt\")\n",
    "            name = \"Sunspot\"\n",
    "            \n",
    "        if problem == 3:\n",
    "            traindata = np.loadtxt(\"datasets/Mackey/train.txt\")\n",
    "            testdata = np.loadtxt(\"datasets/Mackey/test.txt\")\n",
    "            name = \"Mackey\"\n",
    "\n",
    "        x_train = traindata[:, 0:3]\n",
    "        y_train = traindata[:, 4]\n",
    "        x_test = testdata[:, 0:3]\n",
    "        y_test = testdata[:, 4]\n",
    "\n",
    "        mlp_adam = MLPRegressor(hidden_layer_sizes=(5, ), activation='relu', \n",
    "                                solver='adam', alpha=0.1, max_iter=20000, tol=0)\n",
    "        mlp_adam.fit(x_train, y_train)\n",
    "        y_predicttrain = mlp_adam.predict(x_train)\n",
    "        y_predicttest = mlp_adam.predict(x_test)\n",
    "        train_acc = rmse(y_predicttrain, y_train) \n",
    "        test_acc = rmse(y_predicttest, y_test) \n",
    "        print(name, train_acc, test_acc, \"\\n\")\n",
    "\n",
    "        mlp_sgd = MLPRegressor(hidden_layer_sizes=(5, ), activation='relu', \n",
    "                               solver='sgd', alpha=0.1, max_iter=20000, tol=0)\n",
    "        mlp_sgd.fit(x_train, y_train)\n",
    "        y_predicttrain = mlp_sgd.predict(x_train)\n",
    "        y_predicttest = mlp_sgd.predict(x_test)\n",
    "        train_acc = rmse(y_predicttrain,y_train) \n",
    "        test_acc = rmse(y_predicttest, y_test) \n",
    "        print(name, train_acc, test_acc, \"\\n\")\n",
    "\n",
    "        rf = RandomForestRegressor()\n",
    "        rf.fit(x_train, y_train)\n",
    "        y_predicttrain = rf.predict(x_train)\n",
    "        y_predicttest = rf.predict(x_test)\n",
    "        train_acc = rmse(y_predicttrain, y_train) \n",
    "        test_acc = rmse(y_predicttest, y_test)\n",
    "        print(name, train_acc, test_acc, \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eea490e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
