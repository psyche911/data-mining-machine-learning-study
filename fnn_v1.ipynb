{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c818d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, Topo, Train, Test, MaxTime, Samples, MinPer, learnRate):\n",
    "        self.Top = Topo       # NN topology [input, hidden, output]\n",
    "        self.Max = MaxTime    # max epocs\n",
    "        self.TrainData = Train\n",
    "        self.TestData = Test\n",
    "        self.Samples = Samples\n",
    "        self.learn_rate = learnRate\n",
    "        self.minPerf = MinPer\n",
    "        \n",
    "        # initialize weights (W1 W2) and bias (b1 b2) of the network\n",
    "        np.random.seed()\n",
    "        \n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (self.Top[0], self.Top[1]))\n",
    "        #print(\"self.W1: \\n\", self.W1)\n",
    "        self.B1 = np.random.uniform(-0.5, 0.5, (self.Top[1]))    # bias for first layer\n",
    "        #print(\"self.B1: \\n\", self.B1)\n",
    "        self.BestB1 = self.B1\n",
    "        self.BestW1 = self.W1\n",
    "        \n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (self.Top[1], self.Top[2]))\n",
    "        #print(\"self.W2: \\n\", self.W2)\n",
    "        self.B2 = np.random.uniform(-0.5, 0.5, (self.Top[2]))    # bias for second layer\n",
    "        #print(\"self.B2: \\n\", self.B2)\n",
    "        self.BestB2 = self.B2\n",
    "        self.BestW2 = self.W2\n",
    "        \n",
    "        self.hidout = np.zeros(self.Top[1])    # output of first hidden layer\n",
    "        self.out = np.zeros(self.Top[2])       # output of last layer\n",
    "        \n",
    "        self.hid_delta = np.zeros(self.Top[1])   # output of first hidden layer\n",
    "        self.out_delta = np.zeros(self.Top[2])   # output of last layer\n",
    "        \n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    \n",
    "    def sampleEr(self, actualout):\n",
    "        error = np.subtract(self.out, actualout)\n",
    "        sqerror = np.sum(np.square(error)) / self.Top[2]\n",
    "        \n",
    "    \n",
    "    def ForwardPass_Simple(self, input_vec):   # alternative implementation of ForwardPass(self, X)\n",
    "        layer = 0    # input to hidden layer\n",
    "        weightsum_first = 0\n",
    "        \n",
    "        for y in range(self.Top[layer+1]):\n",
    "            for x in range(self.Top[layer]):\n",
    "                weightsum_first += input_vec[x] * self.W1[x, y]\n",
    "            self.hidout[y] = self.sigmoid(weightsum_first - self.B1[y])\n",
    "            weightsum_first = 0\n",
    "            \n",
    "        layer = 1    # hidden layer to output\n",
    "        weightsum_second = 0    # output of second layer (class outputs)\n",
    "        for y in range(self.Top[layer+1]):\n",
    "            for x in range(self.Top[layer]):\n",
    "                weightsum_second += self.hidout[x] * self.W2[x, y]\n",
    "            self.out[y] = self.sigmoid(weightsum_second - self.B2[y])\n",
    "            weightsum_second = 0\n",
    "            \n",
    "    def BackwardPass_Simple(self, input_vec, desired):  # alternative implementation of BackwardPass(self, input, desired)\n",
    "        \n",
    "        # compute gradients for each layer (output and hidden layers)\n",
    "        layer = 2    # output layer\n",
    "        for x in range(self.Top[layer]):\n",
    "            self.out_delta[x] = (desired[x] - self.out[x]) * (self.out[x] * (1 - self.out[x]))\n",
    "        \n",
    "        layer = 1   # hidden to output\n",
    "        for x in range(self.Top[layer]):\n",
    "            for y in range(self.Top[layer+1]):\n",
    "                temp += self.out_delta[y] * self.W2[x,y]\n",
    "            self.hid_delta[x] = (self.hidout[x] * (1 - self.hidout[x])) * temp\n",
    "            temp = 0\n",
    "        \n",
    "        # update weights and bias\n",
    "        layer = 1   # hidden to output\n",
    "        for x in range(self.Top[layer]):\n",
    "            for y in range(self.Top[layer+1]):\n",
    "                self.W2[x, y] += self.learn_rate * self.out_delta[y] * self.hidout[x]\n",
    "                #print(self.W2)\n",
    "        \n",
    "        for y in range(self.Top[layer+1]):\n",
    "            self.B2[y] += -1 * self.learn_rate * self.out_delta[y]\n",
    "            \n",
    "        layer = 0   # input to hidden\n",
    "        for x in range(self.Top[layer]):\n",
    "            for y in range(self.Top[layer+1]):\n",
    "                self.W1[x, y] += self.learn_rate * self.hid_delta[y] * input_vec[x]\n",
    "                \n",
    "        for y in range(self.Top[layer+1]):\n",
    "            self.B1[y] += -1 * self.learn_rate * self.hid_delta[y]\n",
    "            \n",
    "            \n",
    "    def TestNetwork(self, Data, testSize, tolerance):\n",
    "        Input = np.zeros((1, self.Top[0]))    # temp hold input\n",
    "        Desired = np.zeros((1, self.Top[2]))\n",
    "        nOutput = np.zeros((1, self.Top[2]))\n",
    "        clasPerf = 0        \n",
    "        sse = 0        \n",
    "        self.W1 = self.BestW1\n",
    "        self.W2 = self.BestW2    # load best knowledge\n",
    "        self.B1 = self.BestB1\n",
    "        self.B2 = self.BestB2    # load best knowledge\n",
    "        \n",
    "        for s in range(testSize):\n",
    "            Input = Data[s, :self.Top[0]]\n",
    "            Desired = Data[s, self.Top[0]:]\n",
    "            \n",
    "            self.ForwardPass_Simple(Input)\n",
    "            sse += self.sampleEr(Desired)\n",
    "            \n",
    "            pred_binary = np.where(self.out > (1 - tolerance), 1, 0)\n",
    "            \n",
    "            if (Desired == pred_binary).all():\n",
    "                clasPerf += 1\n",
    "                \n",
    "            #if np.isclose(self.out, Desired, atol=erTolerance).any():\n",
    "                #clasPerf += 1\n",
    "                \n",
    "        return sse/testSize, float(clasPerf)/testSize*100\n",
    "        \n",
    "    \n",
    "    def saveKnowledge(self):\n",
    "        self.BestW1 = self.W1\n",
    "        self.BestW2 = self.W2\n",
    "        self.BestB1 = self.B1\n",
    "        self.BestB2 = self.B2\n",
    "        \n",
    "    \n",
    "    def BP_GD(self):\n",
    "        Er = []\n",
    "        epoch = 0\n",
    "        bestmse = 10000   # assign a large number in begining to maintain best (lowest RMSE)\n",
    "        bestTrain = 0\n",
    "        while epoch < self.Max and bestTrain < self.minPerf:\n",
    "            sse = 0\n",
    "            for s in range(self.NumSamples):\n",
    "                Input = self.TrainData[s, :self.Top[0]]\n",
    "                Desired = self.TrainData[s,self.Top[0]:]  \n",
    "\n",
    "                self.ForwardPass_Simple(Input)  \n",
    "\n",
    "                self.BackwardPass_Simple(Input ,Desired)\n",
    "\n",
    "                sse += self.sampleEr(Desired)\n",
    "\n",
    "            mse = np.sqrt(sse/self.NumSamples*self.Top[2])\n",
    "\n",
    "            if mse < bestmse and epoch %10:\n",
    "                bestmse = mse\n",
    "                print('bestmse, epoch: ', bestmse, epoch)\n",
    "                self.saveKnowledge() \n",
    "                (x, bestTrain) = self.TestNetwork(self.TrainData, self.NumSamples, 0.2)\n",
    "\n",
    "            Er = np.append(Er, mse)\n",
    "\n",
    "            epoch += 1\n",
    "\n",
    "        return (Er, bestmse, bestTrain, epoch)\n",
    "\n",
    "\n",
    "def normalisedata(data, inputsize, outsize): \n",
    "    # normalise the data between [0,1]\n",
    "    traindt = data[:, np.array(range(inputsize))]\n",
    "    dt = np.amax(traindt, axis=0)\n",
    "    tds = abs(traindt/dt) \n",
    "    return np.concatenate((tds[:, range(inputsize)], data[:, range(inputsize, inputsize+outsize)]), axis=1)\n",
    "\n",
    "def main(): \n",
    "    problem = 1    # [1,2,3] choose your problem (Iris classfication or 4-bit parity or XOR gate)\n",
    "\n",
    "    if problem == 1:\n",
    "        TrDat = np.loadtxt(\"data/train.csv\", delimiter=',')   # Iris classification problem (UCI dataset)\n",
    "        TesDat = np.loadtxt(\"data/test.csv\", delimiter=',')\n",
    "        Hidden = 6\n",
    "        Input = 4\n",
    "        Output = 2\n",
    "        '''\n",
    "        https://stats.stackexchange.com/questions/207049/neural-network-for-binary-classification-use-1-or-2-output-neurons\n",
    "        '''\n",
    "        TrSamples = TrDat.shape[0]\n",
    "        TestSize = TesDat.shape[0]\n",
    "        learnRate = 0.1  \n",
    "        TrainData = normalisedata(TrDat, Input, Output) \n",
    "        TestData = normalisedata(TesDat, Input, Output)\n",
    "        MaxTime = 500\n",
    "\n",
    "    elif problem == 2:\n",
    "        TrainData = np.loadtxt(\"data/4bit.csv\", delimiter=',')    # 4-bit parity problem\n",
    "        TestData = np.loadtxt(\"data/4bit.csv\", delimiter=',')\n",
    "        Hidden = 6\n",
    "        Input = 4\n",
    "        Output = 1\n",
    "        '''\n",
    "        https://stats.stackexchange.com/questions/207049/neural-network-for-binary-classification-use-1-or-2-output-neurons\n",
    "        '''\n",
    "        TrSamples =  TrainData.shape[0]\n",
    "        TestSize = TestData.shape[0]\n",
    "        learnRate = 0.9\n",
    "        MaxTime = 1000\n",
    "\n",
    "    elif problem == 3:\n",
    "        TrainData = np.loadtxt(\"data/xor_onehotencoding.csv\", delimiter=',') #  XOR  problem\n",
    "        TestData = np.loadtxt(\"data/xor_onehotencoding.csv\", delimiter=',') #  \n",
    "        Hidden = 3\n",
    "        Input = 2\n",
    "        Output = 2  # one hot encoding: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/\n",
    "        TrSamples = TrainData.shape[0]\n",
    "        TestSize = TestData.shape[0]\n",
    "        learnRate = 0.5\n",
    "        MaxTime = 500 \n",
    "\n",
    "    print('TrainData: \\n', TrainData)\n",
    "\n",
    "    Topo = [Input, Hidden, Output] \n",
    "    MaxRun = 2 # number of experimental runs \n",
    "\n",
    "    MinCriteria = 95 #stop when learn 95 percent\n",
    "\n",
    "    trainTolerance = 0.2 # [eg 0.15 would be seen as 0] [ 0.81 would be seen as 1]\n",
    "    testTolerance = 0.49\n",
    "\n",
    "    trainPerf = np.zeros(MaxRun)\n",
    "    testPerf = np.zeros(MaxRun)\n",
    "\n",
    "    trainMSE = np.zeros(MaxRun)\n",
    "    testMSE = np.zeros(MaxRun)\n",
    "    Epochs = np.zeros(MaxRun)\n",
    "    Time = np.zeros(MaxRun)\n",
    "\n",
    "    for run in range(0, MaxRun):\n",
    "        print('experimental run: \\n', run) \n",
    "\n",
    "        fnn = Network(Topo, TrainData, TestData, MaxTime, TrSamples, MinCriteria, learnRate)\n",
    "        start_time=time.time()\n",
    "        (erEp, trainMSE[run], trainPerf[run], Epochs[run]) = fnn.BP_GD()   \n",
    "\n",
    "        Time[run] = time.time() - start_time\n",
    "        (testMSE[run], testPerf[run]) = fnn.TestNetwork(TestData, TestSize, testTolerance)\n",
    "    print('Classification performance for each experimental run: ') \n",
    "    print(trainPerf)\n",
    "    print(testPerf)\n",
    "    \n",
    "    print('RMSE performance for each experimental run: ') \n",
    "    print(trainMSE)\n",
    "    print(testMSE)\n",
    "    \n",
    "    print('Epocs and Time taken for each experimental run: ') \n",
    "    print(Epochs)\n",
    "    print(Time)\n",
    "    \n",
    "    print('Mean and std of training performance: ')\n",
    "    print(np.mean(trainPerf), np.std(trainPerf))\n",
    "    print(np.mean(testPerf), np.std(testPerf))\n",
    "\n",
    "    print('Mean and std of computational time taken: ')\n",
    "    print(np.mean(Time), np.std(Time))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(erEp )\n",
    "    plt.ylabel('error')  \n",
    "    plt.savefig('out.png')\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
