{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135423d4",
   "metadata": {},
   "source": [
    "A vectorised version of the forward pass that uses dot products for computing weighted sum and calculating the gradients in the backward pass. Note that sigmoid units used in hidden layers and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0b61e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: http://iamtrask.github.io/2015/07/12/basic-python-network/  \n",
    "# Sigmoid units used in hidden and output\n",
    "# Numpy used: http://cs231n.github.io/python-numpy-tutorial/#numpy-arrays\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "import time\n",
    " \n",
    "class Network:\n",
    "\n",
    "    def __init__(self, Topo, Train, Test, MaxTime, Samples, MinPer, learnRate): \n",
    "        self.Top  = Topo      # NN topology [input, hidden, output]\n",
    "        self.Max = MaxTime    # max epocs\n",
    "        self.TrainData = Train\n",
    "        self.TestData = Test\n",
    "        self.NumSamples = Samples\n",
    "        self.learn_rate = learnRate\n",
    "        self.minPerf = MinPer\n",
    "\n",
    "        #initialize weights (W1 W2) and bias (b1 b2) of the network\n",
    "        np.random.seed() \n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (self.Top[0], self.Top[1]))  \n",
    "        #print(self.W1, ' self.W1')\n",
    "        self.B1 = np.random.uniform(-0.5, 0.5, (1, self.Top[1]))  # bias first layer\n",
    "        #print(self.B1, ' self.B1')\n",
    "        self.BestB1 = self.B1\n",
    "        self.BestW1 = self.W1\n",
    "        \n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (self.Top[1], self.Top[2]))   \n",
    "        self.B2 = np.random.uniform(-0.5, 0.5, (1, self.Top[2]))  # bias second layer\n",
    "        self.BestB2 = self.B2\n",
    "        self.BestW2 = self.W2 \n",
    "        \n",
    "        self.hidout = np.zeros(self.Top[1])   # output of first hidden layer\n",
    "        self.out = np.zeros(self.Top[2])       # output last layer\n",
    "\n",
    "        self.hid_delta = np.zeros(self.Top[1]) # output of first hidden layer\n",
    "        self.out_delta = np.zeros(self.Top[2])  # output last layer\n",
    "\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "    def softmax(self, x):\n",
    "        # Numerically stable with large exponentials\n",
    "        exps = np.exp(x - x.max())\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "    \n",
    "\n",
    "    def sampleEr(self,actualout):\n",
    "        error = np.subtract(self.out, actualout)\n",
    "        sqerror = np.sum(np.square(error))/self.Top[2] \n",
    "\n",
    "        return sqerror\n",
    "    \n",
    "\n",
    "    def ForwardPass(self, X): \n",
    "        z1 = X.dot(self.W1) - self.B1  \n",
    "        self.hidout = self.sigmoid(z1)  # output of first hidden layer   \n",
    "        z2 = self.hidout.dot(self.W2) - self.B2 \n",
    "        self.out = self.sigmoid(z2)     # output second hidden layer\n",
    "        \n",
    "\n",
    "    def BackwardPass(self, input_vec, desired):\n",
    "        \n",
    "        # error gradient in output layer: out_delta = sum((t_d-o_d)*o_d*(1-o_d)*x_i,d)\n",
    "        out_delta = (desired - self.out) * (self.out * (1 - self.out))\n",
    "        \n",
    "        # error gradient in hidden layer: hid_delta = sum(hidout*(1-hidout)*sum(out_delta*weight_h,o))\n",
    "        hid_delta = out_delta.dot(self.W2.T) * (self.hidout * (1 - self.hidout))\n",
    "        '''\n",
    "        https://www.tutorialspoint.com/numpy/numpy_dot.htm\n",
    "        https://www.geeksforgeeks.org/numpy-dot-python/\n",
    "        '''\n",
    "        self.W2 += self.hidout.T.dot(out_delta) * self.learn_rate   # weights correction = alpha*sum(hidout*out_delta)\n",
    "        self.B2 += (-1 * self.learn_rate * out_delta)    # bias correction = alpha*(-1)*out_delta\n",
    "\n",
    "        self.W1 += (input_vec.T.dot(hid_delta) * self.learn_rate)  # weights correction = alpha*sum(input*hid_delta)\n",
    "        self.B1 += (-1 * self.learn_rate * hid_delta)    # bias correction = alpha*(-1)*hid_delta\n",
    "\n",
    "\n",
    "    def TestNetwork(self, Data, testSize, tolerance):\n",
    "        Input = np.zeros((1, self.Top[0]))    # temp hold input\n",
    "        Desired = np.zeros((1, self.Top[2])) \n",
    "        nOutput = np.zeros((1, self.Top[2]))\n",
    "        clasPerf = 0\n",
    "        sse = 0  \n",
    "        self.W1 = self.BestW1\n",
    "        self.W2 = self.BestW2   # load best knowledge\n",
    "        self.B1 = self.BestB1\n",
    "        self.B2 = self.BestB2   # load best knowledge\n",
    "\n",
    "        for s in range(0, testSize):\n",
    "            Input = Data[s,0:self.Top[0]] \n",
    "            Desired = Data[s,self.Top[0]:] \n",
    "\n",
    "            self.ForwardPass(Input ) \n",
    "            sse += self.sampleEr(Desired)  \n",
    "\n",
    "            pred_binary = np.where(self.out > (1 - tolerance), 1, 0)\n",
    "\n",
    "            if((Desired==pred_binary).all()):\n",
    "                clasPerf = clasPerf +1   \n",
    "\n",
    "            #if(np.isclose(self.out, Desired, atol=erTolerance).any()):\n",
    "                #clasPerf = clasPerf +1  \n",
    "\n",
    "        return (sse/testSize, float(clasPerf)/testSize * 100)\n",
    "\n",
    "\n",
    "    def saveKnowledge(self):\n",
    "        self.BestW1 = self.W1\n",
    "        self.BestW2 = self.W2\n",
    "        self.BestB1 = self.B1\n",
    "        self.BestB2 = self.B2\n",
    "        \n",
    "\n",
    "    def BP_GD(self):\n",
    "        Input = np.zeros((1, self.Top[0]))   # temp hold input\n",
    "        Desired = np.zeros((1, self.Top[2])) \n",
    "\n",
    "        Er = [] \n",
    "        epoch = 0\n",
    "        bestmse = 10000     # assign a large number in begining to maintain best (lowest RMSE)\n",
    "        bestTrain = 0\n",
    "        while epoch < self.Max and bestTrain < self.minPerf :\n",
    "            sse = 0\n",
    "            for s in range(0, self.NumSamples):\n",
    "                Input[:] = self.TrainData[s,0:self.Top[0]]  \n",
    "                Desired[:] = self.TrainData[s,self.Top[0]:]  \n",
    "\n",
    "                self.ForwardPass(Input)  \n",
    "                self.BackwardPass(Input ,Desired)\n",
    "                sse = sse+ self.sampleEr(Desired)\n",
    "\n",
    "            mse = np.sqrt(sse/self.NumSamples*self.Top[2])\n",
    "\n",
    "            if mse < bestmse:\n",
    "                bestmse = mse\n",
    "                print(bestmse, epoch, ' bestmse epoch')\n",
    "                self.saveKnowledge()\n",
    "                (x,bestTrain) = self.TestNetwork(self.TrainData, self.NumSamples, 0.2)\n",
    "\n",
    "            Er = np.append(Er, mse)\n",
    "\n",
    "            epoch += 1  \n",
    "\n",
    "        return (Er, bestmse, bestTrain, epoch) \n",
    "\n",
    "\n",
    "def normalisedata(data, inputsize, outsize):    # normalise the data between [0,1]\n",
    "    traindt = data[:,np.array(range(0,inputsize))]\n",
    "    dt = np.amax(traindt, axis=0)\n",
    "    tds = abs(traindt/dt) \n",
    "    return np.concatenate((tds[:,range(0,inputsize)], data[:,range(inputsize,inputsize+outsize)]), axis=1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    problem = 1    # [1,2,3] choose your problem (Iris classfication or 4-bit parity or XOR gate)\n",
    "    \n",
    "    if problem == 1:\n",
    "        TrDat = np.loadtxt(\"data/train.csv\", delimiter=',')   # Iris classification problem (UCI dataset)\n",
    "        TesDat = np.loadtxt(\"data/test.csv\", delimiter=',') \n",
    "        Hidden = 6\n",
    "        Input = 4\n",
    "        Output = 2\n",
    "        '''\n",
    "        https://stats.stackexchange.com/questions/207049/neural-network-for-binary-classification-use-1-or-2-output-neurons\n",
    "        '''\n",
    "        TrSamples = TrDat.shape[0]\n",
    "        TestSize = TesDat.shape[0]\n",
    "        learnRate = 0.1  \n",
    "        TrainData = normalisedata(TrDat, Input, Output) \n",
    "        TestData = normalisedata(TesDat, Input, Output)\n",
    "        MaxTime = 500\n",
    "\n",
    "    elif problem == 2:\n",
    "        TrainData = np.loadtxt(\"data/4bit.csv\", delimiter=',')   # 4-bit parity problem\n",
    "        TestData = np.loadtxt(\"data/4bit.csv\", delimiter=',')\n",
    "        Hidden = 6\n",
    "        Input = 4\n",
    "        Output = 1\n",
    "        '''\n",
    "        https://stats.stackexchange.com/questions/207049/neural-network-for-binary-classification-use-1-or-2-output-neurons\n",
    "        '''\n",
    "        TrSamples = TrainData.shape[0]\n",
    "        TestSize = TestData.shape[0]\n",
    "        learnRate = 0.9 \n",
    "        MaxTime = 1000\n",
    "\n",
    "    elif problem == 3:\n",
    "        TrainData = np.loadtxt(\"data/xor.csv\", delimiter=',')    # XOR problem\n",
    "        TestData = np.loadtxt(\"data/xor.csv\", delimiter=',')  \n",
    "        Hidden = 3\n",
    "        Input = 2\n",
    "        Output = 2\n",
    "        '''one hot encoding: https://machinelearningmastery.com/how-to-one-hot-encode-sequence-data-in-python/'''\n",
    "        TrSamples = TrainData.shape[0]\n",
    "        TestSize = TestData.shape[0]\n",
    "        learnRate = 0.5\n",
    "        MaxTime = 500\n",
    "\n",
    "    Topo = [Input, Hidden, Output] \n",
    "    MaxRun = 3    # number of experimental runs \n",
    "\n",
    "    MinCriteria = 95    #stop when learn 95 percent\n",
    "\n",
    "    trainTolerance = 0.2    # [e.g. 0.15 would be seen as 0] [0.81 would be seen as 1]\n",
    "    testTolerance = 0.49\n",
    "\n",
    "    trainPerf = np.zeros(MaxRun)\n",
    "    testPerf = np.zeros(MaxRun)\n",
    "\n",
    "    trainMSE = np.zeros(MaxRun)\n",
    "    testMSE = np.zeros(MaxRun)\n",
    "    Epochs = np.zeros(MaxRun)\n",
    "    Time = np.zeros(MaxRun)\n",
    "\n",
    "    for run in range(0, MaxRun  ):\n",
    "        print(run, ' is experimental run') \n",
    "\n",
    "        fnn = Network(Topo, TrainData, TestData, MaxTime, TrSamples, MinCriteria, learnRate)\n",
    "        start_time=time.time()\n",
    "        (erEp, trainMSE[run], trainPerf[run], Epochs[run]) = fnn.BP_GD()   \n",
    "\n",
    "        Time[run] = time.time() - start_time\n",
    "        (testMSE[run], testPerf[run]) = fnn.TestNetwork(TestData, TestSize, testTolerance)\n",
    "    print('\\n print classification performance for each experimental run') \n",
    "    print(trainPerf)\n",
    "    print(testPerf)\n",
    "    \n",
    "    print('\\n print RMSE performance for each experimental run') \n",
    "    print(trainMSE)\n",
    "    print(testMSE)\n",
    "    \n",
    "    print('\\n print Epocs and Time taken for each experimental run') \n",
    "    print(Epochs)\n",
    "    print(Time)\n",
    "    \n",
    "    print('\\n print mean and std of training performance') \n",
    "    print(np.mean(trainPerf), np.std(trainPerf))\n",
    "    print(np.mean(testPerf), np.std(testPerf))\n",
    "\n",
    "    print('\\n print mean and std of computational time taken') \n",
    "    print(np.mean(Time), np.std(Time))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(erEp )\n",
    "    plt.ylabel('error')  \n",
    "    plt.savefig('out.png')\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
