{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7ba782",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Data Wraggling\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Statistics\n",
    "from math import sqrt\n",
    "# Visualisation\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcdd589",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.target = mnist.target.astype(np.uint8)\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7170454b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5d141c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7bf2825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      2812\n",
      "           1       0.98      0.99      0.99      3179\n",
      "           2       0.96      0.97      0.96      2787\n",
      "           3       0.97      0.95      0.96      2815\n",
      "           4       0.96      0.97      0.96      2678\n",
      "           5       0.97      0.96      0.96      2523\n",
      "           6       0.97      0.98      0.98      2740\n",
      "           7       0.97      0.96      0.97      2927\n",
      "           8       0.95      0.95      0.95      2716\n",
      "           9       0.95      0.95      0.95      2823\n",
      "\n",
      "    accuracy                           0.97     28000\n",
      "   macro avg       0.97      0.97      0.97     28000\n",
      "weighted avg       0.97      0.97      0.97     28000\n",
      "\n",
      "Confusion Report\n",
      "[[2767    1    2    0    3    4   12    1   22    0]\n",
      " [   0 3143   13    4    5    3    3    2    4    2]\n",
      " [   9    2 2698   11   12    1   13   22   18    1]\n",
      " [   2    2   37 2670    3   31    2   24   29   15]\n",
      " [   6    5    4    1 2587    1   13    5    9   47]\n",
      " [   4    5    5   32    4 2419   20    3   20   11]\n",
      " [  12    5    2    0    6   17 2691    0    7    0]\n",
      " [   2    9   39    2   12    1    0 2822    3   37]\n",
      " [   4   20   14   17   15   18   10    1 2584   33]\n",
      " [  11    6   10   29   38   11    3   25   14 2676]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print (\"Classification Report\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print (\"Confusion Report\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33f60f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scipy_models(X_train, X_test, y_train, y_test, type_model, hidden, learn_rate, run_num, problem):\n",
    "\n",
    "    print(run_num, ' is our exp run')\n",
    "\n",
    "    tree_depth = 2\n",
    "\n",
    "    if problem == 'classifification':\n",
    "        if type_model == 0:   # SGD \n",
    "            model = MLPClassifier(hidden_layer_sizes=(hidden,), random_state=run_num, \n",
    "                                  max_iter=100, solver='sgd', learning_rate_init=learn_rate) \n",
    "            #model.fit(x_train, y_train)\n",
    "\n",
    "        elif type_model == 1:  # https://scikit-learn.org/stable/modules/tree.html (see how tree can be visualised)\n",
    "            model = DecisionTreeClassifier(random_state=0, max_depth=tree_depth)\n",
    "            #model.fit(x_train, y_train)\n",
    "\n",
    "        elif type_model == 2:\n",
    "            model = RandomForestClassifier(n_estimators=100, max_depth=tree_depth, random_state=run_num)\n",
    "\n",
    "        elif type_model == 3:\n",
    "            model = ExtraTreesClassifier(n_estimators=100, max_depth=tree_depth, random_state=run_num)\n",
    "\n",
    "    elif problem == 'regression':\n",
    "        if type_model == 0:  # SGD  \n",
    "            model = MLPRegressor(hidden_layer_sizes=(hidden*3,), random_state=run_num, \n",
    "                                 max_iter=500, solver='adam', learning_rate_init=learn_rate) \n",
    "\n",
    "        elif type_model == 1:  \n",
    "            model = DecisionTreeRegressor(random_state=0, max_depth=tree_depth)\n",
    "\n",
    "        elif type_model == 2: \n",
    "            model = RandomForestRegressor(n_estimators=100, max_depth=tree_depth, random_state=run_num)\n",
    "\n",
    "        elif type_model == 3: \n",
    "            model = ExtraTreeRegressor(n_estimators=100, max_depth=tree_depth, random_state=run_num)            \n",
    "\n",
    "    # Train the model using the training sets\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    if type_model == 1:\n",
    "        r = export_text(model)\n",
    "        print(r)\n",
    "\n",
    "    # Make predictions using the testing set\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_train = model.predict(X_train) \n",
    "\n",
    "    if problem == 'regression':\n",
    "        perf_test = np.sqrt(mean_squared_error(y_test, y_pred_test)) \n",
    "        perf_train = np.sqrt(mean_squared_error(y_train, y_pred_train)) \n",
    "\n",
    "    if problem == 'classifification': \n",
    "        perf_test = accuracy_score(y_pred_test, y_test) \n",
    "        perf_train = accuracy_score(y_pred_train, y_train) \n",
    "        cm = confusion_matrix(y_pred_test, y_test) \n",
    "        clf_report = classification_report(y_pred_test, y_pred)\n",
    "        #auc = roc_auc_score(y_pred_test, y_test, average=None)\n",
    "\n",
    "        print (\"Classification Report\")\n",
    "        print(clf_report)\n",
    "\n",
    "        print (\"Confusion Matrix\")\n",
    "        print(cm)\n",
    "\n",
    "    return perf_test #,perf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bce1b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimen_reduction(X_train, X_test, type_model):\n",
    "    #Scikit-learn is using SVD for PCA\n",
    "\n",
    "    if type_model == 0:     # SVD solver - full\n",
    "        pca = PCA(n_components=3, svd_solver='full')    # SVD LAPACK Solver\n",
    "        \n",
    "    elif type_model == 1:   # SVD \n",
    "        pca = PCA(n_components=3, svd_solver='arpack')  # SVD AROACK Solver\n",
    "\n",
    "    # note number of components can be changed to 0.95\n",
    "    # but since we have different train and test data - that can create problems\n",
    "    # it is best to combine both train and test data and then split them back again\n",
    "\n",
    "    #data = np.vstack((X_train, X_test)) # something along these lines\n",
    "\n",
    "    #print(data.shape, ' * ')\n",
    "\n",
    "    reduced_datatrain = pca.fit_transform(X_train)\n",
    "    train_varianceratio = pca.explained_variance_ratio_\n",
    "\n",
    "    reduced_datatest = pca.fit_transform(X_test)\n",
    "    test_varianceratio = pca.explained_variance_ratio_\n",
    "\n",
    "    return reduced_datatrain, reduced_datatest, test_varianceratio, train_varianceratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4fbb41b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduced_datatrain\n",
      "[[ 679.06301885  589.70823428 -375.60773342]\n",
      " [  77.30070459  380.28195552  152.5007241 ]\n",
      " [-105.01086736  789.61934053 -692.72012798]\n",
      " ...\n",
      " [ -77.96816142 -462.90931971   41.19684075]\n",
      " [-763.49329536  629.85667268  182.792218  ]\n",
      " [-543.64919452  315.71084172  449.52166693]]\n",
      "variance_scoretrain\n",
      "[0.09781175 0.07168405 0.06089555]\n",
      "classifification  is our problem\n",
      "0  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.21     28000\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.11      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "0  is our exp run\n",
      "|--- feature_350 <= 125.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_350 >  125.50\n",
      "|   |--- feature_489 <= 27.50\n",
      "|   |   |--- class: 3\n",
      "|   |--- feature_489 >  27.50\n",
      "|   |   |--- class: 1\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46      6977\n",
      "           1       0.87      0.55      0.67      5056\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.76      0.43      0.55      4874\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.89      0.23      0.37     11093\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35     28000\n",
      "   macro avg       0.33      0.15      0.21     28000\n",
      "weighted avg       0.84      0.35      0.48     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2232  100 1761  184  105  737  922  110  762   64]\n",
      " [  42 2754  424  198  102  128  310  128  772  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 173  156  159 2065  113  925  252  111  528  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 365  169  443  368 2358  733 1256 2578  654 2169]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "0  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.62      0.76      4469\n",
      "           1       0.99      0.51      0.67      6238\n",
      "           2       0.64      0.77      0.70      2347\n",
      "           3       0.59      0.71      0.64      2282\n",
      "           4       0.78      0.50      0.61      4157\n",
      "           5       0.04      1.00      0.08       106\n",
      "           6       0.62      0.87      0.72      1962\n",
      "           7       0.85      0.68      0.75      3665\n",
      "           8       0.43      0.85      0.57      1383\n",
      "           9       0.28      0.58      0.38      1391\n",
      "\n",
      "    accuracy                           0.63     28000\n",
      "   macro avg       0.62      0.71      0.59     28000\n",
      "weighted avg       0.78      0.63      0.67     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2720    2  198  245   57  710  356   58   78   45]\n",
      " [   5 3136  524  589   61  448  263  191  885  136]\n",
      " [  14   27 1765  105   28   34   97   67  193   17]\n",
      " [   4    3   20 1599    3  523   23    0   79   28]\n",
      " [   7    2   52   57 2073  220  197  121   92 1336]\n",
      " [   0    0    0    1    0  105    0    0    0    0]\n",
      " [  17    1   56    8   66   55 1681    0   54   24]\n",
      " [  31    7  128  123  155  157   95 2456   72  441]\n",
      " [  12    1   43   35   17  101    5   17 1130   22]\n",
      " [   2    0    1   53  218  170   23   17  133  774]]\n",
      "0  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.69      0.81      3901\n",
      "           1       0.99      0.51      0.68      6204\n",
      "           2       0.68      0.81      0.74      2373\n",
      "           3       0.74      0.65      0.69      3153\n",
      "           4       0.71      0.62      0.66      3062\n",
      "           5       0.03      0.99      0.07        88\n",
      "           6       0.63      0.88      0.73      1975\n",
      "           7       0.87      0.62      0.73      4056\n",
      "           8       0.43      0.88      0.58      1313\n",
      "           9       0.43      0.65      0.52      1875\n",
      "\n",
      "    accuracy                           0.66     28000\n",
      "   macro avg       0.65      0.73      0.62     28000\n",
      "weighted avg       0.79      0.66      0.69     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2680    2  130  112   38  347  364   70  104   54]\n",
      " [  11 3146  440  481  135  372  300  207  892  220]\n",
      " [  20    8 1876   59   21   76  135   48  127    3]\n",
      " [   6    9   67 2009   13  799   25    2  171   52]\n",
      " [   1    0   44   19 1883  158   40   66   36  815]\n",
      " [   0    0    0    0    0   87    0    0    0    1]\n",
      " [  45    1   45    2   80   38 1703    2   35   24]\n",
      " [  39   13  148   87  270  286  161 2507   96  449]\n",
      " [   7    0   35   15   13   89   10    8 1122   14]\n",
      " [   3    0    2   31  225  271    2   17  133 1191]]\n",
      "0  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     28000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.10      0.18     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "0  is our exp run\n",
      "|--- feature_0 <= -717.82\n",
      "|   |--- feature_1 <= 38.16\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  38.16\n",
      "|   |   |--- class: 1\n",
      "|--- feature_0 >  -717.82\n",
      "|   |--- feature_1 <= -270.53\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  -270.53\n",
      "|   |   |--- class: 3\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.01      0.00       190\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.23      0.04      0.06     17740\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.03      0.01      0.01     10070\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03     28000\n",
      "   macro avg       0.03      0.00      0.01     28000\n",
      "weighted avg       0.16      0.03      0.04     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    1    5   18    0    0  100    1   64]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1816  183 1389  693 2632 1685 2347 2737 1557 2701]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 996 2995 1397 2117   28  838  393   90 1158   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "0  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.71      0.50      1537\n",
      "           1       0.87      0.82      0.84      3427\n",
      "           2       0.37      0.10      0.16     10396\n",
      "           3       0.14      0.09      0.11      4403\n",
      "           4       0.00      0.00      0.00      3200\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.03      0.27      0.06       319\n",
      "           7       0.00      0.01      0.01      2136\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00      2582\n",
      "\n",
      "    accuracy                           0.19     28000\n",
      "   macro avg       0.18      0.20      0.17     28000\n",
      "weighted avg       0.29      0.19      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[1086    0   60    4   40   40  229    3   42   33]\n",
      " [   0 2775   16   17   86   22   21  287   15  188]\n",
      " [ 475   38 1038  172 1864  955 1820 1664  839 1531]\n",
      " [ 156   69   68  402  682  514   68  940  453 1051]\n",
      " [ 700   26  840  469    3  348  340    8  462    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  35    3   86   16    1   43   87    1   45    2]\n",
      " [   3  267  581  449    2  133  153   24  518    6]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 357    1   98 1286    0  468   22    0  342    8]]\n",
      "0  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.66      0.70      3152\n",
      "           1       0.64      0.22      0.32      9482\n",
      "           2       0.01      0.05      0.01       364\n",
      "           3       0.19      0.11      0.14      4633\n",
      "           4       0.00      0.00      0.00       693\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.31      0.28      0.30      3080\n",
      "           7       0.01      0.00      0.00      6142\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       454\n",
      "\n",
      "    accuracy                           0.20     28000\n",
      "   macro avg       0.19      0.13      0.15     28000\n",
      "weighted avg       0.37      0.20      0.24     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2073    0  228   53   33  134  449    2  137   43]\n",
      " [  53 2044  352  142 1702  549  728 1924  392 1596]\n",
      " [  13    0   19    2  108   15   60   44   14   89]\n",
      " [ 124   10   48  519  791  597  180  899  404 1061]\n",
      " [  68   10  180  118    1  101   77    3  135    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 329    5  838   92   40  414  863   22  462   15]\n",
      " [  98 1110 1113 1687    3  577  381   33 1123   17]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  54    0    9  202    0  136    2    0   49    2]]\n",
      "1  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      1.00      0.30       496\n",
      "           1       1.00      0.12      0.21     27504\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.13     28000\n",
      "   macro avg       0.12      0.11      0.05     28000\n",
      "weighted avg       0.99      0.13      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 495    0    0    0    0    0    0    1    0    0]\n",
      " [2317 3179 2787 2815 2678 2523 2740 2926 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "1  is our exp run\n",
      "|--- feature_350 <= 125.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_350 >  125.50\n",
      "|   |--- feature_489 <= 27.50\n",
      "|   |   |--- class: 3\n",
      "|   |--- feature_489 >  27.50\n",
      "|   |   |--- class: 1\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46      6977\n",
      "           1       0.87      0.55      0.67      5056\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.76      0.43      0.55      4874\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.89      0.23      0.37     11093\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35     28000\n",
      "   macro avg       0.33      0.15      0.21     28000\n",
      "weighted avg       0.84      0.35      0.48     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2232  100 1761  184  105  737  922  110  762   64]\n",
      " [  42 2754  424  198  102  128  310  128  772  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 173  156  159 2065  113  925  252  111  528  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 365  169  443  368 2358  733 1256 2578  654 2169]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "1  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.60      0.74      4574\n",
      "           1       1.00      0.52      0.69      6093\n",
      "           2       0.66      0.77      0.71      2434\n",
      "           3       0.62      0.71      0.66      2413\n",
      "           4       0.74      0.51      0.61      3875\n",
      "           5       0.05      0.99      0.09       119\n",
      "           6       0.52      0.81      0.64      1774\n",
      "           7       0.90      0.72      0.80      3611\n",
      "           8       0.43      0.87      0.57      1333\n",
      "           9       0.38      0.60      0.46      1774\n",
      "\n",
      "    accuracy                           0.64     28000\n",
      "   macro avg       0.63      0.71      0.60     28000\n",
      "weighted avg       0.78      0.64      0.67     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2707    1  150  213   43  783  467   27  128   55]\n",
      " [  13 3150  483  615   70  376  295  162  806  123]\n",
      " [  17   11 1824   88   30   57  170   51  171   15]\n",
      " [   4    2   22 1673    2  551   33    0   93   33]\n",
      " [   5    2   37   38 1973  220  226   61  133 1180]\n",
      " [   0    0    0    3    0  116    0    0    0    0]\n",
      " [  20    1   68   12   73   40 1427    1  113   19]\n",
      " [  26   11  155  109  131  131   92 2584   35  337]\n",
      " [  19    0   46   23    9   70   19   12 1114   21]\n",
      " [   1    1    2   41  347  179   11   29  123 1040]]\n",
      "1  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.66      0.79      4177\n",
      "           1       0.99      0.49      0.66      6450\n",
      "           2       0.58      0.83      0.68      1977\n",
      "           3       0.75      0.58      0.66      3591\n",
      "           4       0.79      0.54      0.64      3971\n",
      "           5       0.06      1.00      0.12       162\n",
      "           6       0.64      0.87      0.73      2028\n",
      "           7       0.84      0.66      0.74      3740\n",
      "           8       0.35      0.93      0.51      1011\n",
      "           9       0.24      0.75      0.36       893\n",
      "\n",
      "    accuracy                           0.64     28000\n",
      "   macro avg       0.62      0.73      0.59     28000\n",
      "weighted avg       0.81      0.64      0.68     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2729    2  216  128   73  378  402  110   75   64]\n",
      " [  10 3149  620  421  105  409  261  240 1052  183]\n",
      " [   8    8 1600   48   17   19   51   55  154   17]\n",
      " [  10    6   62 2047   10  972   91    6  264  123]\n",
      " [   1    0   42   34 2114  261   68   68  108 1275]\n",
      " [   0    0    0    1    0  161    0    0    0    0]\n",
      " [  18    1   61    5   53   56 1745    2   58   29]\n",
      " [  30   13  167   80  173  200  112 2432   73  460]\n",
      " [   6    0   19   20    7   18    9    6  910   16]\n",
      " [   0    0    0   31  126   49    1    8   22  656]]\n",
      "1  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     28000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.10      0.18     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "1  is our exp run\n",
      "|--- feature_0 <= -717.82\n",
      "|   |--- feature_1 <= 38.16\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  38.16\n",
      "|   |   |--- class: 1\n",
      "|--- feature_0 >  -717.82\n",
      "|   |--- feature_1 <= -270.53\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  -270.53\n",
      "|   |   |--- class: 3\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.01      0.00       190\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.23      0.04      0.06     17740\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.03      0.01      0.01     10070\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03     28000\n",
      "   macro avg       0.03      0.00      0.01     28000\n",
      "weighted avg       0.16      0.03      0.04     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    1    5   18    0    0  100    1   64]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1816  183 1389  693 2632 1685 2347 2737 1557 2701]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 996 2995 1397 2117   28  838  393   90 1158   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "1  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.71      0.51      1572\n",
      "           1       0.87      0.81      0.84      3411\n",
      "           2       0.37      0.10      0.16     10159\n",
      "           3       0.15      0.09      0.11      4644\n",
      "           4       0.00      0.00      0.00      3192\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.04      0.26      0.07       431\n",
      "           7       0.00      0.00      0.00      1922\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00      2669\n",
      "\n",
      "    accuracy                           0.19     28000\n",
      "   macro avg       0.18      0.20      0.17     28000\n",
      "weighted avg       0.29      0.19      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[1114    0   64    4   38   40  236    3   42   31]\n",
      " [   0 2752   14   16   87   21   20  293   15  193]\n",
      " [ 469   35 1028  168 1808  945 1808 1607  826 1465]\n",
      " [ 165   77   73  413  739  522   76  992  473 1114]\n",
      " [ 655   53  822  459    3  349  344   10  493    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  41    5  108   20    1   66  110    4   72    4]\n",
      " [   2  255  565  404    2  106  122   18  444    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 366    2  113 1331    0  474   24    0  351    8]]\n",
      "1  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.49      0.63      5227\n",
      "           1       0.91      0.42      0.58      6868\n",
      "           2       0.01      0.07      0.02       363\n",
      "           3       0.18      0.07      0.10      6668\n",
      "           4       0.00      0.00      0.00      1517\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.27      0.32      0.29      2332\n",
      "           7       0.00      0.00      0.00      4594\n",
      "           8       0.01      0.21      0.02       138\n",
      "           9       0.00      0.00      0.00       293\n",
      "\n",
      "    accuracy                           0.24     28000\n",
      "   macro avg       0.23      0.16      0.16     28000\n",
      "weighted avg       0.46      0.24      0.31     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2514    1  652  162   73  403  990   15  350   67]\n",
      " [  10 2877  197  113  801  369  220 1204  198  879]\n",
      " [   9    0   24    4   81   21   64   66   20   74]\n",
      " [  44    6   47  502 1651  558  174 1568  371 1747]\n",
      " [  80    0  369  452    1  253  138    2  221    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 121    5  514   70   64  371  729   45  380   33]\n",
      " [  29  289  972 1305    5  450  373   26 1127   18]\n",
      " [   4    1    6    5    2   33   52    1   31    3]\n",
      " [   1    0    6  202    0   65    0    0   18    1]]\n",
      "2  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.21     28000\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.11      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "2  is our exp run\n",
      "|--- feature_350 <= 125.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_350 >  125.50\n",
      "|   |--- feature_489 <= 27.50\n",
      "|   |   |--- class: 3\n",
      "|   |--- feature_489 >  27.50\n",
      "|   |   |--- class: 1\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46      6977\n",
      "           1       0.87      0.55      0.67      5056\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.76      0.43      0.55      4874\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.89      0.23      0.37     11093\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35     28000\n",
      "   macro avg       0.33      0.15      0.21     28000\n",
      "weighted avg       0.84      0.35      0.48     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2232  100 1761  184  105  737  922  110  762   64]\n",
      " [  42 2754  424  198  102  128  310  128  772  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 173  156  159 2065  113  925  252  111  528  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 365  169  443  368 2358  733 1256 2578  654 2169]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "2  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      4329\n",
      "           1       1.00      0.54      0.70      5958\n",
      "           2       0.65      0.84      0.73      2206\n",
      "           3       0.68      0.64      0.66      2939\n",
      "           4       0.77      0.54      0.63      3856\n",
      "           5       0.07      0.99      0.12       165\n",
      "           6       0.67      0.83      0.74      2232\n",
      "           7       0.87      0.73      0.79      3440\n",
      "           8       0.43      0.89      0.58      1326\n",
      "           9       0.36      0.66      0.47      1549\n",
      "\n",
      "    accuracy                           0.66     28000\n",
      "   macro avg       0.65      0.73      0.62     28000\n",
      "weighted avg       0.79      0.66      0.69     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2723    1  147  226   49  606  351   76   98   52]\n",
      " [   6 3156  525  459   66  398  255  185  779  129]\n",
      " [   7    5 1802   73   35   19  111   51   84   19]\n",
      " [  10    3   28 1848    3  741   47    5  202   52]\n",
      " [   3    1   42   51 2048  254   75   72  171 1139]\n",
      " [   0    0    0    3    0  162    0    0    0    0]\n",
      " [  19    3   88    6   82   67 1835    4  107   21]\n",
      " [  26    7  133   96  140   81   44 2483   45  385]\n",
      " [  18    2   22   19   15   59   18   15 1137   21]\n",
      " [   0    1    0   34  240  136    4   36   93 1005]]\n",
      "2  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.77      4327\n",
      "           1       1.00      0.49      0.66      6513\n",
      "           2       0.58      0.86      0.69      1881\n",
      "           3       0.78      0.54      0.64      3988\n",
      "           4       0.76      0.55      0.64      3702\n",
      "           5       0.06      1.00      0.11       143\n",
      "           6       0.52      0.86      0.65      1663\n",
      "           7       0.85      0.65      0.74      3786\n",
      "           8       0.37      0.89      0.52      1129\n",
      "           9       0.22      0.73      0.34       868\n",
      "\n",
      "    accuracy                           0.62     28000\n",
      "   macro avg       0.61      0.72      0.58     28000\n",
      "weighted avg       0.80      0.62      0.66     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2718    2  246  120   82  380  482  125   98   74]\n",
      " [   9 3152  663  366  117  402  367  210 1050  177]\n",
      " [   2    5 1575   45   24   17   49   64   75   25]\n",
      " [  20    7   60 2121   56 1069  137   18  272  228]\n",
      " [   1    0   40   26 2024  229  105   56  100 1121]\n",
      " [   0    0    0    1    0  142    0    0    0    0]\n",
      " [  11    1   50    2   51   40 1423    0   60   25]\n",
      " [  44   12  139  106  184  138  138 2439   66  520]\n",
      " [   7    0   14   14   13   31   37   10  970   33]\n",
      " [   0    0    0   14  127   75    2    5   25  620]]\n",
      "2  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     28000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.10      0.18     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "2  is our exp run\n",
      "|--- feature_0 <= -717.82\n",
      "|   |--- feature_1 <= 38.16\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  38.16\n",
      "|   |   |--- class: 1\n",
      "|--- feature_0 >  -717.82\n",
      "|   |--- feature_1 <= -270.53\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  -270.53\n",
      "|   |   |--- class: 3\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.01      0.00       190\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.23      0.04      0.06     17740\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.03      0.01      0.01     10070\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03     28000\n",
      "   macro avg       0.03      0.00      0.01     28000\n",
      "weighted avg       0.16      0.03      0.04     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    1    5   18    0    0  100    1   64]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1816  183 1389  693 2632 1685 2347 2737 1557 2701]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 996 2995 1397 2117   28  838  393   90 1158   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "2  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.70      0.56      1865\n",
      "           1       0.88      0.82      0.85      3432\n",
      "           2       0.37      0.10      0.16     10382\n",
      "           3       0.15      0.09      0.12      4435\n",
      "           4       0.00      0.00      0.00      3547\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.01      0.20      0.02       136\n",
      "           7       0.00      0.00      0.00      1903\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00      2300\n",
      "\n",
      "    accuracy                           0.20     28000\n",
      "   macro avg       0.19      0.19      0.17     28000\n",
      "weighted avg       0.30      0.20      0.22     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[1298    0   64   38   45   90  226    7   57   40]\n",
      " [   0 2784   16   17   84   22   22  285   15  187]\n",
      " [ 486   37 1024  165 1866  943 1820 1672  835 1534]\n",
      " [ 160   69   69  424  676  528   68  931  463 1047]\n",
      " [ 707   39  920  493    4  403  436   14  523    8]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  15    2   29   11    1   27   27    1   23    0]\n",
      " [   3  246  545  374    2  111  125   17  476    4]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 143    2  120 1293    0  399   16    0  324    3]]\n",
      "2  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.59      0.68      3862\n",
      "           1       0.85      0.31      0.46      8681\n",
      "           2       0.02      0.04      0.02      1226\n",
      "           3       0.27      0.13      0.18      5705\n",
      "           4       0.00      0.00      0.00       956\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.32      0.29      0.31      3047\n",
      "           7       0.00      0.00      0.00      4372\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00       151\n",
      "\n",
      "    accuracy                           0.24     28000\n",
      "   macro avg       0.23      0.14      0.16     28000\n",
      "weighted avg       0.46      0.24      0.31     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2251    0  354   99   68  238  583    7  205   57]\n",
      " [  26 2683  307  148 1168  574  495 1667  385 1228]\n",
      " [  30    0   47    5  339   43  229  230   46  257]\n",
      " [ 128   10   67  750 1062  732  210  983  518 1245]\n",
      " [  59    7  181  308    0  171   60    2  167    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 286    6  815  115   40  371  885   23  482   24]\n",
      " [  31  473 1010 1287    1  359  278   15  908   10]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   1    0    6  103    0   35    0    0    5    1]]\n",
      "3  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.21     28000\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.11      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "3  is our exp run\n",
      "|--- feature_350 <= 125.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_350 >  125.50\n",
      "|   |--- feature_489 <= 27.50\n",
      "|   |   |--- class: 3\n",
      "|   |--- feature_489 >  27.50\n",
      "|   |   |--- class: 1\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46      6977\n",
      "           1       0.87      0.55      0.67      5056\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.76      0.43      0.55      4874\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.89      0.23      0.37     11093\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35     28000\n",
      "   macro avg       0.33      0.15      0.21     28000\n",
      "weighted avg       0.84      0.35      0.48     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2232  100 1761  184  105  737  922  110  762   64]\n",
      " [  42 2754  424  198  102  128  310  128  772  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 173  156  159 2065  113  925  252  111  528  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 365  169  443  368 2358  733 1256 2578  654 2169]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "3  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.63      0.77      4359\n",
      "           1       1.00      0.50      0.67      6379\n",
      "           2       0.58      0.84      0.69      1938\n",
      "           3       0.68      0.62      0.65      3064\n",
      "           4       0.76      0.51      0.61      3975\n",
      "           5       0.04      1.00      0.08       101\n",
      "           6       0.54      0.90      0.67      1671\n",
      "           7       0.88      0.69      0.78      3701\n",
      "           8       0.46      0.87      0.60      1434\n",
      "           9       0.31      0.63      0.42      1378\n",
      "\n",
      "    accuracy                           0.64     28000\n",
      "   macro avg       0.62      0.72      0.59     28000\n",
      "weighted avg       0.79      0.64      0.67     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2724    2  243  246   67  527  359   74   64   53]\n",
      " [  12 3160  612  462   91  473  313  178  907  171]\n",
      " [   4    2 1591   57   12   21  108   48   84   11]\n",
      " [  15    2   30 1854    6  814   88    2  196   57]\n",
      " [   3    2   57   46 2020  223  205   62  115 1242]\n",
      " [   0    0    0    1    0  100    0    0    0    0]\n",
      " [   4    2   73    2   22   49 1484    0   21   14]\n",
      " [  34    9  139   94  193  122  141 2538   36  395]\n",
      " [  14    0   41   27   13   88   24   11 1187   29]\n",
      " [   2    0    1   26  254  106   18   14  106  851]]\n",
      "3  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.66      0.78      4157\n",
      "           1       1.00      0.49      0.65      6555\n",
      "           2       0.58      0.82      0.68      1998\n",
      "           3       0.75      0.60      0.67      3452\n",
      "           4       0.78      0.57      0.66      3678\n",
      "           5       0.06      0.99      0.11       147\n",
      "           6       0.66      0.90      0.76      2051\n",
      "           7       0.84      0.64      0.73      3768\n",
      "           8       0.36      0.95      0.52      1031\n",
      "           9       0.30      0.74      0.43      1163\n",
      "\n",
      "    accuracy                           0.64     28000\n",
      "   macro avg       0.63      0.73      0.60     28000\n",
      "weighted avg       0.80      0.64      0.68     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2705    1  293  103   60  424  325   71  108   67]\n",
      " [   9 3156  606  474  115  440  279  250 1016  210]\n",
      " [  17   10 1585   48   20   55   70   39  135   19]\n",
      " [   9    6   49 2041   21  890   77    6  259   94]\n",
      " [   4    0   40   24 2075  174  108  130   64 1059]\n",
      " [   0    0    0    2    0  145    0    0    0    0]\n",
      " [  37    1   55    2   57   40 1808    1   29   21]\n",
      " [  24    5  139   98  200  211   69 2407  112  503]\n",
      " [   7    0   20   13    2   21    4    6  950    8]\n",
      " [   0    0    0   10  128  123    0   17   43  842]]\n",
      "3  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     28000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.10      0.18     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "3  is our exp run\n",
      "|--- feature_0 <= -717.82\n",
      "|   |--- feature_1 <= 38.16\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  38.16\n",
      "|   |   |--- class: 1\n",
      "|--- feature_0 >  -717.82\n",
      "|   |--- feature_1 <= -270.53\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  -270.53\n",
      "|   |   |--- class: 3\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.01      0.00       190\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.23      0.04      0.06     17740\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.03      0.01      0.01     10070\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03     28000\n",
      "   macro avg       0.03      0.00      0.01     28000\n",
      "weighted avg       0.16      0.03      0.04     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    1    5   18    0    0  100    1   64]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1816  183 1389  693 2632 1685 2347 2737 1557 2701]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 996 2995 1397 2117   28  838  393   90 1158   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "3  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.74      0.49      1387\n",
      "           1       0.85      0.82      0.84      3315\n",
      "           2       0.37      0.10      0.16     10370\n",
      "           3       0.15      0.09      0.12      4599\n",
      "           4       0.00      0.00      0.00      3264\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.04      0.25      0.07       437\n",
      "           7       0.00      0.01      0.00      1965\n",
      "           8       0.00      1.00      0.00         1\n",
      "           9       0.00      0.00      0.00      2662\n",
      "\n",
      "    accuracy                           0.19     28000\n",
      "   macro avg       0.18      0.30      0.17     28000\n",
      "weighted avg       0.28      0.19      0.20     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[1016    0   47    4   35   30  191    3   33   28]\n",
      " [   0 2705   13   10   82   17   18  277   15  178]\n",
      " [ 510   35 1030  163 1853  940 1838 1650  830 1521]\n",
      " [ 181   81   74  429  701  545   76  963  473 1076]\n",
      " [ 693   47  846  478    3  349  341    7  497    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  49    3  107   26    2   69  108    3   66    4]\n",
      " [   2  306  551  352    2  122  146   24  454    6]\n",
      " [   0    0    0    0    0    0    0    0    1    0]\n",
      " [ 361    2  119 1353    0  451   22    0  347    7]]\n",
      "3  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.58      0.68      3889\n",
      "           1       0.79      0.29      0.42      8865\n",
      "           2       0.01      0.03      0.02       854\n",
      "           3       0.21      0.10      0.14      5610\n",
      "           4       0.00      0.00      0.00       841\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.28      0.29      0.29      2657\n",
      "           7       0.00      0.00      0.00      4834\n",
      "           8       0.00      0.00      0.00         4\n",
      "           9       0.00      0.00      0.00       446\n",
      "\n",
      "    accuracy                           0.22     28000\n",
      "   macro avg       0.21      0.13      0.15     28000\n",
      "weighted avg       0.43      0.22      0.28     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2251    0  391   63   74  181  674    6  189   60]\n",
      " [  45 2517  406  184 1203  647  637 1529  481 1216]\n",
      " [  12    0   27    1  304   20  100  165   22  203]\n",
      " [ 123    5   60  581 1040  640  223 1171  460 1307]\n",
      " [  43   21  238  150    1  120   86    3  179    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 201    6  698   85   54  347  772   33  436   25]\n",
      " [  90  630  948 1550    2  438  248   20  898   10]\n",
      " [   1    0    1    1    0    1    0    0    0    0]\n",
      " [  46    0   18  200    0  129    0    0   51    2]]\n",
      "4  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.11      0.21     28000\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.11     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.11      0.21     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "4  is our exp run\n",
      "|--- feature_350 <= 125.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- class: 0\n",
      "|--- feature_350 >  125.50\n",
      "|   |--- feature_489 <= 27.50\n",
      "|   |   |--- class: 3\n",
      "|   |--- feature_489 >  27.50\n",
      "|   |   |--- class: 1\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.32      0.46      6977\n",
      "           1       0.87      0.55      0.67      5056\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.76      0.43      0.55      4874\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.89      0.23      0.37     11093\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.35     28000\n",
      "   macro avg       0.33      0.15      0.21     28000\n",
      "weighted avg       0.84      0.35      0.48     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2232  100 1761  184  105  737  922  110  762   64]\n",
      " [  42 2754  424  198  102  128  310  128  772  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 173  156  159 2065  113  925  252  111  528  392]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 365  169  443  368 2358  733 1256 2578  654 2169]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "4  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.64      0.78      4319\n",
      "           1       0.99      0.51      0.67      6249\n",
      "           2       0.62      0.80      0.70      2195\n",
      "           3       0.66      0.65      0.65      2793\n",
      "           4       0.69      0.56      0.61      3326\n",
      "           5       0.06      0.99      0.11       150\n",
      "           6       0.65      0.84      0.73      2128\n",
      "           7       0.86      0.68      0.76      3706\n",
      "           8       0.48      0.88      0.62      1460\n",
      "           9       0.37      0.62      0.46      1674\n",
      "\n",
      "    accuracy                           0.65     28000\n",
      "   macro avg       0.64      0.72      0.61     28000\n",
      "weighted avg       0.78      0.65      0.68     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2737    2  222  243   40  532  358   52   82   51]\n",
      " [   4 3143  512  498   86  518  235  240  861  152]\n",
      " [  10   15 1718   70   32   25  135   50  123   17]\n",
      " [   2    3   52 1785    4  739   34    1  134   39]\n",
      " [   4    2   40   48 1832  154  101   64   70 1011]\n",
      " [   0    0    0    2    0  148    0    0    0    0]\n",
      " [  17    5   95    9   95   54 1771    2   51   29]\n",
      " [  25    6  109   92  222  133   83 2481   65  490]\n",
      " [  13    2   38   22   18   74   11   18 1240   24]\n",
      " [   0    1    1   46  349  146   12   19   90 1010]]\n",
      "4  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.75      4421\n",
      "           1       1.00      0.50      0.67      6341\n",
      "           2       0.57      0.79      0.66      2013\n",
      "           3       0.67      0.59      0.63      3125\n",
      "           4       0.71      0.54      0.62      3498\n",
      "           5       0.06      0.99      0.11       155\n",
      "           6       0.58      0.84      0.69      1923\n",
      "           7       0.85      0.61      0.71      4033\n",
      "           8       0.41      0.90      0.56      1227\n",
      "           9       0.29      0.64      0.40      1264\n",
      "\n",
      "    accuracy                           0.62     28000\n",
      "   macro avg       0.61      0.70      0.58     28000\n",
      "weighted avg       0.78      0.62      0.66     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2690    4  257  199   58  533  451   72  105   52]\n",
      " [   5 3150  609  523   88  308  283  233  973  169]\n",
      " [   5    8 1562   45   35   46   96   59  136   21]\n",
      " [   9    4   27 1818   32  791   82   12  171  179]\n",
      " [   2    2   57   41 1890  193   56   93   90 1074]\n",
      " [   0    0    0    3    0  152    0    0    0    0]\n",
      " [  35    1   60    3   98   49 1594    3   54   26]\n",
      " [  56    9  193  148  242  246  147 2439   64  489]\n",
      " [  10    1   21   16    9   52   28   10 1060   20]\n",
      " [   0    0    1   19  226  153    3    6   63  793]]\n",
      "4  is our exp run\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.10      0.18     28000\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.00      0.00      0.00         0\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.10     28000\n",
      "   macro avg       0.10      0.01      0.02     28000\n",
      "weighted avg       1.00      0.10      0.18     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2812 3179 2787 2815 2678 2523 2740 2927 2716 2823]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "4  is our exp run\n",
      "|--- feature_0 <= -717.82\n",
      "|   |--- feature_1 <= 38.16\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  38.16\n",
      "|   |   |--- class: 1\n",
      "|--- feature_0 >  -717.82\n",
      "|   |--- feature_1 <= -270.53\n",
      "|   |   |--- class: 7\n",
      "|   |--- feature_1 >  -270.53\n",
      "|   |   |--- class: 3\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.01      0.00       190\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.23      0.04      0.06     17740\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.03      0.01      0.01     10070\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.03     28000\n",
      "   macro avg       0.03      0.00      0.01     28000\n",
      "weighted avg       0.16      0.03      0.04     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    1    1    5   18    0    0  100    1   64]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [1816  183 1389  693 2632 1685 2347 2737 1557 2701]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 996 2995 1397 2117   28  838  393   90 1158   58]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0]]\n",
      "4  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.73      0.55      1710\n",
      "           1       0.87      0.82      0.84      3417\n",
      "           2       0.37      0.10      0.16     10521\n",
      "           3       0.15      0.09      0.12      4470\n",
      "           4       0.00      0.00      0.00      3949\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.03      0.25      0.06       370\n",
      "           7       0.00      0.00      0.00      1189\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00      2374\n",
      "\n",
      "    accuracy                           0.20     28000\n",
      "   macro avg       0.19      0.20      0.17     28000\n",
      "weighted avg       0.30      0.20      0.22     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[1237    0   50   33   34   75  192    4   51   34]\n",
      " [   0 2771   14   15   85   22   22  285   15  188]\n",
      " [ 526   37 1046  170 1876  953 1858 1673  845 1537]\n",
      " [ 170   68   69  427  677  536   71  933  471 1048]\n",
      " [ 689  144  964  549    5  422  442   21  707    6]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [  42    3   93   21    1   53   94    1   59    3]\n",
      " [   1  154  411  271    0   56   46   10  237    3]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 147    2  140 1329    0  406   15    0  331    4]]\n",
      "4  is our exp run\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66      4029\n",
      "           1       0.84      0.33      0.48      8033\n",
      "           2       0.01      0.03      0.02      1196\n",
      "           3       0.34      0.14      0.20      6583\n",
      "           4       0.00      0.00      0.00       995\n",
      "           5       0.00      0.00      0.00         0\n",
      "           6       0.31      0.28      0.29      3011\n",
      "           7       0.00      0.00      0.00      3971\n",
      "           8       0.00      0.06      0.00        17\n",
      "           9       0.00      0.00      0.00       165\n",
      "\n",
      "    accuracy                           0.24     28000\n",
      "   macro avg       0.23      0.14      0.17     28000\n",
      "weighted avg       0.47      0.24      0.31     28000\n",
      "\n",
      "Confusion Matrix\n",
      "[[2231    0  425   80   62  175  767    5  229   55]\n",
      " [  22 2665  299  144 1062  486  356 1542  297 1160]\n",
      " [  16    0   35    6  411   38  175  219   37  259]\n",
      " [ 239   12   78  937 1093  901  258 1097  651 1317]\n",
      " [  45    3  248  283    0  171   74    1  169    1]\n",
      " [   0    0    0    0    0    0    0    0    0    0]\n",
      " [ 227    9  804  107   50  418  838   41  494   23]\n",
      " [  18  489  888 1178    0  291  260   21  819    7]\n",
      " [   0    0    1    0    0    2   12    1    1    0]\n",
      " [  14    1    9   80    0   41    0    0   19    1]]\n",
      "[0.11353571 0.13121429 0.11353571 0.11353571 0.11353571]  nn_all\n",
      "0.11707142857142858  mean nn_all\n",
      "0.007071428571428578  std nn_all\n",
      "[0.34389286 0.34389286 0.34389286 0.34389286 0.34389286]  tree_all\n",
      "0.34389285714285717  tree_all\n",
      "0.0  tree_all\n",
      "[0.62282143 0.62885714 0.64996429 0.62532143 0.63803571] 8  forest_all\n",
      "0.633  forest_all\n",
      "0.009928468653116555  forest_all\n",
      "[0.65014286 0.62653571 0.61371429 0.63264286 0.61242857]  extra tree_all\n",
      "0.6270928571428572  extra tree_all\n",
      "0.013830711168575935  extra tree_all\n",
      "[0.10042857 0.10042857 0.10042857 0.10042857 0.10042857]  nn pca_all\n",
      "0.10042857142857142  mean nn pca_all\n",
      "0.0  std nn pca_all\n",
      "[0.028 0.028 0.028 0.028 0.028]  tree_all\n",
      "0.028000000000000004  tree pca_all\n",
      "3.469446951953614e-18  tree pca_all\n",
      "[0.19367857 0.1945     0.19932143 0.19010714 0.19978571] 8  forest pca_all\n",
      "0.19547857142857145  forest pca_all\n",
      "0.0036433192984151232  forest pca_all\n",
      "[0.19835714 0.23946429 0.23685714 0.22039286 0.24032143]  extra tree pca_all\n",
      "0.2270785714285714  extra tree pca_all\n",
      "0.01608737938603438  extra tree pca_all\n"
     ]
    }
   ],
   "source": [
    "def main(): \n",
    "\n",
    "    max_expruns = 5\n",
    "\n",
    "    nn_all = np.zeros(max_expruns) \n",
    "    forest_all = np.zeros(max_expruns) \n",
    "    tree_all = np.zeros(max_expruns) \n",
    "    extratree_all = np.zeros(max_expruns)\n",
    "    \n",
    "    nnpca_all = np.zeros(max_expruns) \n",
    "    forestpca_all = np.zeros(max_expruns) \n",
    "    treepca_all = np.zeros(max_expruns) \n",
    "    extratreepca_all = np.zeros(max_expruns) \n",
    " \n",
    "    learn_rate = 0.01\n",
    "    hidden = 8\n",
    "    \n",
    "    # 0 is for PCA (you can try 1 for case of SVD)\n",
    "    [reduced_datatrain, reduced_datatest, variance_scoretrain, variance_scoretest] = dimen_reduction(X_train, X_test, 0)    \n",
    "    print('reduced_datatrain')\n",
    "    print(reduced_datatrain)\n",
    "    print('variance_scoretrain')\n",
    "    print(variance_scoretrain)\n",
    "    \n",
    "    # classifcation accurary is reported for classification and RMSE for regression\n",
    "    prob = 'classifification' \n",
    "    #prob = 'regression'\n",
    "\n",
    "    print(prob, ' is our problem') \n",
    " \n",
    "    for run_num in range(0, max_expruns):    \n",
    "        \n",
    "        acc_nn = scipy_models(X_train, X_test, y_train, y_test, 0, hidden, learn_rate, run_num, prob)    # SGD \n",
    "        acc_tree = scipy_models(X_train, X_test, y_train, y_test, 1, hidden, learn_rate, run_num, prob)  # Decision Tree\n",
    "        acc_forest = scipy_models(X_train, X_test, y_train, y_test, 2, hidden, learn_rate, run_num, prob) # Random Forests\n",
    "        acc_extratree = scipy_models(X_train, X_test, y_train, y_test, 3, hidden, learn_rate, run_num, prob) # Extra Trees\n",
    "       \n",
    "        nn_all[run_num] = acc_nn \n",
    "        tree_all[run_num] = acc_tree\n",
    "        forest_all[run_num] = acc_forest\n",
    "        extratree_all[run_num] = acc_extratree        \n",
    "        \n",
    "        # after PCA        \n",
    "        acc_nnpca = scipy_models(reduced_datatrain, reduced_datatest, y_train, y_test, 0, hidden, learn_rate, run_num, prob)\n",
    "        acc_treepca = scipy_models(reduced_datatrain, reduced_datatest, y_train, y_test, 1, hidden, learn_rate, run_num, prob) \n",
    "        acc_forestpca = scipy_models(reduced_datatrain, reduced_datatest, y_train, y_test, 2, hidden, learn_rate, run_num, prob) \n",
    "        acc_extratreepca = scipy_models(reduced_datatrain, reduced_datatest, y_train, y_test, 3, hidden, learn_rate, run_num, prob)\n",
    "        \n",
    "        nnpca_all[run_num] = acc_nnpca\n",
    "        treepca_all[run_num] = acc_treepca\n",
    "        forestpca_all[run_num] = acc_forestpca\n",
    "        extratreepca_all[run_num] = acc_extratreepca\n",
    "        \n",
    "    print(nn_all,' nn_all')\n",
    "    print(np.mean(nn_all), ' mean nn_all')\n",
    "    print(np.std(nn_all), ' std nn_all')\n",
    " \n",
    "    print(tree_all, ' tree_all')\n",
    "    print(np.mean(tree_all), ' tree_all')\n",
    "    print(np.std(tree_all), ' tree_all')\n",
    "\n",
    "    print(forest_all, hidden,' forest_all')\n",
    "    print(np.mean(forest_all), ' forest_all')\n",
    "    print(np.std(forest_all), ' forest_all')\n",
    "\n",
    "    print(extratree_all, ' extra tree_all')\n",
    "    print(np.mean(extratree_all), ' extra tree_all')\n",
    "    print(np.std(extratree_all), ' extra tree_all')\n",
    "    \n",
    "    \n",
    "    print(nnpca_all,' nn pca_all')\n",
    "    print(np.mean(nnpca_all), ' mean nn pca_all')\n",
    "    print(np.std(nnpca_all), ' std nn pca_all')\n",
    " \n",
    "    print(treepca_all, ' tree_all')\n",
    "    print(np.mean(treepca_all), ' tree pca_all')\n",
    "    print(np.std(treepca_all), ' tree pca_all')\n",
    "\n",
    "    print(forestpca_all, hidden,' forest pca_all')\n",
    "    print(np.mean(forestpca_all), ' forest pca_all')\n",
    "    print(np.std(forestpca_all), ' forest pca_all')\n",
    "\n",
    "    print(extratreepca_all, ' extra tree pca_all')\n",
    "    print(np.mean(extratreepca_all), ' extra tree pca_all')\n",
    "    print(np.std(extratreepca_all), ' extra tree pca_all')\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "     main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3021f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Let's start by generating some blobs ---\n",
    "blob_centers = np.array(\n",
    "    [[ 0.2,  2.3], [-1.5,  0.6], [-1.5 ,  2.3], \n",
    "     [-2.8,  1.8], [-2.8,  2.8], [-2.8,  1.3]])\n",
    "\n",
    "blob_std = np.array([0.4, 0.5, 0.3, 0.1, 0.1, 0.1])\n",
    "\n",
    "X, y = make_blobs(n_samples=2000, centers=blob_centers, cluster_std=blob_std, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "226ec990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.69823941,  1.3454702 ],\n",
       "       [-2.87459835,  1.8097575 ],\n",
       "       [ 0.96077126,  1.17046777],\n",
       "       [-1.92096971,  2.30673708],\n",
       "       [-2.72483644,  1.68358492]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47dbdbcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 3, 0, 2, 3])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27c63fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('from sklearn.preprocessing import StandardScaler\\nimport numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.73803632, -0.6184501 ],\n",
       "       [-0.89379375, -0.03106759],\n",
       "       [ 2.49354422, -0.83985044],\n",
       "       [-0.05156396,  0.59767482],\n",
       "       [-0.76152639, -0.19069195]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Machine learning algorithms need to consider all features on an even playing field. \n",
    "# The values for all features must be transformed to the same scale.\n",
    "# Feature scaling: The process of transforming numerical features to use the same scale.\n",
    "# Important data preprocessing step for most distance-based machine learning algorithms.\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "scaled_features[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7b5fc4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choosing the Appropriate Number of Clusters\n",
    "# elbow method: run several k-means, increment k with each iteration, and record the SSE\n",
    "\n",
    "kmeans_kwargs = {\n",
    "    \"init\": \"random\", \n",
    "    \"n_init\": 10, \n",
    "    \"max_iter\": 300, \n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "# A list holds the SSE values for each k\n",
    "sse = []\n",
    "for k in range(1, 9):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_features)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    \n",
    "# Plot SSE vs. number of clusters: SSE continues to decrease as increase k\n",
    "# elbow point: x-value of this point is thought to be a reasonable trade-off between error and number of clusters\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(1, 9), sse)\n",
    "plt.xticks(range(1, 9))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52d7ea3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining the elbow point in the SSE curve\n",
    "from kneed import KneeLocator\n",
    "\n",
    "kl = KneeLocator(range(1, 9), sse, curve=\"convex\", direction=\"decreasing\")\n",
    "kl.elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df48c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette_scores: \n",
      " [0.41659610179128287, 0.4556562913388938, 0.5573014801937737, 0.6230912487490905, 0.6041992855789394, 0.5969511789377605, 0.5715933165377429]\n",
      "k_max:  5 \n",
      "score_max:  0.6230912487490905\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Choosing the Appropriate Number of Clusters\n",
    "# silhouette coefficient: a measure of cluster cohesion and separation, values range between -1 and 1\n",
    "# silhouette coefficient = (b-a)/max(a, b)\n",
    "# a is the mean distance to the other instances in the same cluster\n",
    "# b is the mean nearest-cluster distance\n",
    "\n",
    "# A list holds the silhouette coefficients for each k\n",
    "silhouette_coefficients = []\n",
    "\n",
    "# Start at 2 clusters for silhouette coefficient\n",
    "for k in range(2, 9):\n",
    "    kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
    "    kmeans.fit(scaled_features)\n",
    "    score = silhouette_score(scaled_features, kmeans.labels_)\n",
    "    silhouette_coefficients.append(score)\n",
    "\n",
    "print('silhouette_scores: \\n', silhouette_coefficients)\n",
    "score_max = np.max(silhouette_coefficients)\n",
    "k_max = np.argmax(silhouette_coefficients) + 2\n",
    "print('k_max: ', k_max, '\\nscore_max: ' , score_max)    \n",
    "\n",
    "# Plotting the average silhouette scores for each k \n",
    "# The best choice for k with the maximum score\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.plot(range(2, 9), silhouette_coefficients)\n",
    "plt.xticks(range(2, 9))\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Coefficient\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb0c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bcbec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
